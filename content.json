{"posts":[{"title":"2023年智能芯片领域会议概览","text":"为了准确把握每一个学术交流（摸鱼）的机会，本文收集了智能芯片领域（固态电路、体系结构等）的相关学术会议的投稿信息，包括召开时间、地点、截稿时间等。之后，我将尽量保持本文持续更新。 由于多数会议的投稿截稿时间都会延期一至两周，因此下表中的截稿时间通常只是个大约时间。 固态电路 会议 地点 召开时间 截稿时间 网站链接 ISSCC’23 San Francisco, CA, US 2023.02.19 2022.09.07 Link VLSI’23 Kyoto, Japan 2023.06.11 2023.02.01 Link ESSCIRC’23 Lisbon, Portugal 2023.09.11 2023.04.14 Link ASSCC’23 Haikou, China 2023.11.05 2023.06.05 Link CICC’23 San Antonio, TX, US 2023.04.23 2022.11.14 Link HOTCHIPS’23 San Francisco, CA, US 2023.08.27 2023.03.22 Link 体系结构 会议 地点 召开时间 截稿时间 网站链接 ISCA’23 Orlando, FL, USA 2023.06.17 2022.11.14 Link MICRO’23 Toronto, Canada 2023.10.28 2023.04.21 Link HPCA’23 Montreal, Canada 2023.02.25 2022.08.01 Link DAC’23 San Francisco, CA, US 2023.07.09 2022.11.14 Link 机器视觉 会议 地点 召开时间 截稿时间 网站链接 CVPR’23 Vancouver, Canada 2023.06.18 2022.11.04 Link IROS’23 Detroit, MI, US 2023.10.01 2023.03.01 Link ICRA’23 London, UK 2023.05.29 2022.08.05 Link 其他会议 会议 地点 召开时间 截稿时间 网站链接 ISCAS’23 Monterey, CA, US 2023.05.21 2022.11.07 Link AICAS’23 Hangzhou, China 2023.06.11 2023.02.03 Link APCCAS’23 Hyderabad, India 2023.11.20 2023.06.04 Link MWSCAS’23 Phoenix, AZ, US 2023.04.07 2022.08.06 Link BioCAS’23 Toronta, Canada 2023.10.19 2023.06.09 Link GLSVLSI’23 Knoxville, TN, US 2023.06.05 2023.02.06 Link ICCAD’23 San Francisco, CA, US 2023.10.29 2023.05.15 Link ASP-DAC’23 Tokyo, Japan 2023.01.16 2022.07.24 Link DATE’23 Antwerp, Belgium 2023.04.17 2022.09.18 Link MLSys’23 Southern FL, US 2023.06.04 2022.10.28 Link FPGA’23 Monterey, CA, US 2023.02.12 2022.09.23 Link FPT’23 Yokohama, Japan 2023.12.11 2023.07.14 Link FPL’23 Gothenburg, Sweden 2023.09.04 2023.03.13 Link 祝大家投稿顺利～ photoed by Birmingham Museums","link":"/Research/asic-conf-ddl-2023/"},{"title":"2024年智能芯片领域会议概览","text":"为了准确把握每一个学术交流（摸鱼）的机会，本文收集了 2024 年智能芯片领域（固态电路、体系结构等）的相关学术会议的投稿信息，包括召开时间、地点、截稿时间等。 历史版本： 2023年智能芯片领域会议概览 由于多数会议的投稿截稿时间都会延期一至两周，因此下表中的截稿时间通常只是个大约时间。表中空白位置是还没有公布的信息，我会继续更新。 固态电路 会议 地点 召开时间 截稿时间 网站链接 ISSCC San Francisco, CA, US 2024.02.18 2023.09.06 Link VLSI Honolulu, HI, US 2024.06.12 Link ESSERC* Bruges, Belgium 2024.09.09 2024.04.05 Link ASSCC CICC Denver, CO, US 2024.04.21 2023.11.06 Link HOTCHIPS Link * 欧洲固态电路会议（ESSCIRC）和欧洲固态器件研究会议（ESSDERC）从 2024 年起合并为欧洲固态电子研究会议（ESSERC）。 体系结构 会议 地点 召开时间 截稿时间 网站链接 ISCA Buenos Aires, Argentina 2024.06.29 2023.11.14 Link MICRO Link HPCA Edinburgh, Scotland 2024.03.02 2023.07.28 Link DAC San Francisco, CA, US 2024.06.23 2023.11.13 Link 机器视觉 会议 地点 召开时间 截稿时间 网站链接 CVPR Seattle, WA, US 2024.06.17 2023.11.03 Link IROS Link ICRA Yokohama, Japan 2024.05.13 2023.09.15 Link 其他会议 会议 地点 召开时间 截稿时间 网站链接 ISCAS Singapore 2024.05.19 2023.10.15 Link AICAS Dubai, UAE 2024.04.15 2023.10.15 Link APCCAS Taipei, Taiwan 2024.11.07 Link MWSCAS Western Springfield, MA, US 2024.08.11 2024.03.22 Link BIOCAS Link GLSVLSI Link ICCAD Link ASP-DAC Incheon, South Korea 2024.01.22 2023.07.28 Link DATE Valencia, Spain 2024.03.25 2023.09.10 Link FPGA Monterey, CA, US 2024.03.03 2023.10.13 Link 祝大家投稿顺利～ photoed by Birmingham Museums","link":"/Research/asic-conf-ddl-2024/"},{"title":"🐿️ Chipmunk - 下降沿触发寄存器 RegNeg","text":"chipmunk 提供了在时钟负沿触发的寄存器 RegNegNext 和 RegNegEnable。它们具有和chisel3.RegNext、chisel3.util.RegEnable 类似的接口，唯一的区别是其在时钟的下降沿（而不是上升沿）完成数据锁存。 Why？Chisel 已经提供了一系列的时钟上升沿触发的寄存器，包括 RegInit、RegNext、RegEnable 等。有些场合下我们需要生成一些时钟下降沿采样的寄存器，但现阶段在 Chisel 中我们只能采用 BlackBox 的方法实现。 关于 Chisel 是否应该添加对时钟下降沿触发寄存器的原生支持，社区在 FIRRTL 时代就进行过一些讨论（如 #695）。尽管 Chisel 现在的后端 CIRCT Firtool 是支持生成 negedge clock 电路的，但目前 Chisel 前端还没有对应的结构。 Usagechipmunk 提供了四种不同签名的下降沿触发寄存器： Code Snippet1234RegNegNext(next: T)RegNegNext(next: T, init: T, isResetAsync: Boolean = true)RegNegEnable(next: T, enable: Bool)RegNegEnable(next: T, init: T, enable: Bool, isResetAsync: Boolean = true) 它们的参数功能如下： next：待锁存的输入数据，会在时钟的下降沿被采样。 init：复位初始数据；需要上下文中存在复位信号。 enable：锁存使能信号，当它为true.B时next会被锁存。 isResetAsync：复位信号是否为异步复位（AsyncReset）；默认为true。 用户不需要在参数列表中给定时钟和复位信号，和 Chisel 的 RegXXX 一样，它们会根据上下文使用对应的时钟和复位信号。 唯一需要注意的是参数isResetAsync。由于 Chisel 的类型系统限制，同步复位和异步复位的类型都是ResetType（除非显式声明为AsyncReset()，但这种情况不常见），Chisel 会在 Elaboration 阶段再推导决定它们属于哪种类型的复位信号并赋予对应的类型：Bool 或 AsyncReset。Chisel 没有提供公开 API 判断复位类型，因此需要用户通过设置 isResetAsync 告诉 RegNeg 最终使用哪种复位。 下面给出一些实际用例供参考。 Code Snippet12345678val nextVal0 = Wire(Vec(8, UInt(3.W)))val nextVal1 = Wire(SInt(3.W))val enable1 = Wire(Bool())withClockAndReset(clock, reset) { val r0 = RegNegNext(io.nextVal0, init = VecInit(Seq.fill(8)(1.U(3.W)))) val r1 = RegNegEnable(io.nextVal1, -3.S, io.enable1)} See Also Chipmunk Github photoed by Annegret Kammer","link":"/Engineering/chipmunk-regneg/"},{"title":"🐿️ Chipmunk - 用 Master&#x2F;Slave 定义 Bundle 方向","text":"chipmunk.IsMasterSlave 使用户在定义 Bundle 时可同时规定其属于数据的生产者（Master）或消费者（Slave）。当以 Master() 定义的 Bundle 被以 Slave() 形式例化时，内部信号的方向会自动翻转，反之亦然。 Why？chisel3.Bundle 在例化时，可以使用 Flipped() 翻转其内部信号的方向。在许多Chisel项目中，我们约定 Bundle 作为模块端口时默认是生产者，如果我们希望它作为消费者，则显式地用 Flipped() 把它包裹起来。然而，很多用户并不总是遵守这一约定，所以用户经常搞不清楚端口需不需要用 Flipped() 包裹起来。实践中，对于别人代码中的模块接口，通常需要阅读其代码和文档才能判断这些 Bundle 属于 Master 还是 Slave（是否需要翻转其方向）。 例如，如下代码片段中的 SRAM 读写接口 SramReadWriteIO 看起来非常合理，但根据上述约定，这一接口既然属于Slave，其内部信号方向应该反过来定义（比如 enable 应当是 Output()）。不遵守约定的结果，就是其他用户在调用这一 Bundle 的的时候经常会陷入困惑：我应不应该套上 Flipped()？ Code Snippet1234567class SramReadWriteIO extends Bundle { val enable = Input(Bool()) val read = Input(Bool()) val addr = Input(UInt(16.W)) val dataIn = Input(UInt(32.W)) val dataOut = Output(UInt(32.W))} Usagechipmunk.IsMasterSlave 是一个特质，用户在定义 Bundle 时可以选择混入这一特质。它要求额外定义一方法 def isMaster: Boolean，true 表示该 Bundle 当前的信号方向属于 Master，反之属于 Slave。 Code Snippet123456class SramWriteIO extends Bundle with IsMasterSlave { val enable = Input(Bool()) val addr = Input(UInt(16.W)) val dataIn = Input(UInt(32.W)) def isMaster = false // This is a Slave Bundle} 如此一来，在例化它时，用户可以用 Master() 或 Slave() 来选择它内部信号的方向。对于一个套上 Slave() 的 Master Bundle，其内部信号方向会相应取反。用户不需要关心何时需要 Flipped，只需要记住这一 Bundle 在当前模块的数据传输关系。 Code Snippet123456class Sram extends Module { val io = new Bundle { val rw = Slave(new SramReadWriteIO) } // ...} 此外，Master/Slave 还支持嵌套使用，从而允许用户构造出如下 AMBA AXI 总线这样的复杂例子。 Code Snippet123456789101112131415class AxiIO extends Bundle with IsMasterSlave { val aw = Master(new AxiWriteAddrChannelIO) val ar = Master(new AxiReadAddrChannelIO) val r = Slave(new AxiReadDataChannelIO) val w = Master(new AxiWriteDataChannelIO) val b = Slave(new AxiWriteRespChannelIO) def isMaster = true}class AxiSlave extends Module { val io = IO(new Bundle { val axi = Slave(new AxiIO) }) // ...} See Also Chipmunk Github photoed by Annegret Kammer","link":"/Engineering/chipmunk-master-slave/"},{"title":"🐿️ Chipmunk - Bits&#x2F;Data 等的更多方法","text":"chipmunk 为 Chisel 的原生类型 Bits/Data 等增加了若干额外的方法（主要是语法糖），为用户提供了一些更加便捷的编码选择，提高代码的可读性。 chisel3.Bits 的额外方法chisel3.Bits 是 Chisel 的 UInt/SInt/Bool 等类型的父类，因此以下方法可以被这些类型的实例调用。 这些方法是在 chipmunk.AddMethodsToBits 这个隐式类中实现的。 msb/lsb — 获取信号的最高/低 n 比特chisel3.Bits 已提供了类似的方法 x.head(n) 和 x.tail(n)，其中前者是获取该信号的高 n 比特，后者是去掉该信号的高 n 比特（相当于 x.head(x.getWidth - n)）。这两个方法显然是来自函数式编程语言处理队列的习惯（Haskell 用户狂喜），但和绝大多数硬件工程师的习惯很不一致，且导致代码可读性降低。硬件工程师习惯用“某某信号的高N比特/低N比特”来对多比特信号进行切片。 因此，Chipmunk 提供了 x.msb(n) 和 x.lsb(n) 两组方法，它们的功能正如方法名（most/least significant bits）：前者 x.msb(n) 和 x.head(n) 行为类似，后者 x.lsb(n) 则是获取该信号的低 n 比特。 具体如下： def msb(n: Int = 1): UInt返回当前信号实例的最高 n 比特。 def lsb(n: Int = 1): UInt返回当前信号实例的最低 n 比特。 def msb: Bool返回当前信号实例的最高 1 比特，注意返回类型为 Bool，与 msb() 不同。 def lsb: Bool返回当前信号实例的最高 1 比特，注意返回类型为 Bool，与 lsb() 不同。 setAll/clearAll/setAllTo — 将信号的所有比特赋 1 或 0将一个信号的所有比特赋 1 或 0 是一个很普遍的需求，SystemVerilog 中引入了专门的语法： Code Snippet12assign allOnes = '1;assign allZeros = '0; Chisel 中赋全 0 是容易实现的（x := 0.U），但赋全 1 缺乏优雅易读的实现方法。常见的写法包括： Code Snippet12x1 := Fill(x1.getWidth, b).asTypeOf(x1)x2 := ~ 0.U // ~ 0.S if SInt 无论如何，都很不直观。特别是如果我希望将所有比特赋值为某个 Bool 信号或某个 Scala Boolean 变量输出时，代码会变得更加难以阅读。 因此，Chipmunk 提供了 setAll/clearAll/setAllTo 等一系列方法。具体如下： def setAllTo(b: Bool): T将信号的每个比特都赋值为 b，并返回该信号。 def setAllTo(b: Boolean): T将信号的每个比特都赋值为 b 的 Bool 字面量（即b.B），并返回该信号。 def setAll(): T将信号的每个比特都赋值为 true.B，并返回该信号。 def clearAll(): T将信号的每个比特都赋值为 false.B，并返回该信号。 isOneHot — 判断当前信号是否为独热码（one-hot）如方法名的字面意思，判断当前信号是否为独热码。若是则输出 true.B，反之则输出 false.B。 chisel3.Data 的额外方法chisel3.Data 是 Chisel 的各硬件类型的父类。 这些方法是在 chipmunk.AddMethodsToData 这个隐式类中实现的。 dontTouch — dontTouch() 的语法糖chisel3.dontTouch 可以阻止 Chisel 对该信号进行优化，常用于保留某中间信号的命名、保留与模块输出无关的电路等。这是一个单例对象，下面是 Chisel 提供的一个用法等例子： Code Snippet123456789class MyModule extends Module { val io = IO(new Bundle { val a = Input(UInt(32.W)) val b = Output(UInt(32.W)) }) io.b := io.a val dead = RegNext(io.a +% 1.U) // normally dead would be pruned by DCE dontTouch(dead) // Marking it as such will preserve it} Chipmunk 提供了一个方法版本，可以直接调用 Data 类型的 dontTouch 方法实现同样的效果，为用户提供更多的编码选择。因此，上面的代码也可以写成下面这样，在有的时候这可以节省代码量。 Code Snippet12345678class MyModule extends Module { val io = IO(new Bundle { val a = Input(UInt(32.W)) val b = Output(UInt(32.W)) }) io.b := io.a val dead = RegNext(io.a +% 1.U).dontTouch} See Also Chipmunk Github photoed by Annegret Kammer","link":"/Engineering/chipmunk-bits-misc/"},{"title":"🐿️ Chipmunk Docs - DecoupledIO 增强版之 StreamIO","text":"在数字电路设计中，我们经常使用 Ready/Valid 握手协议来解耦数据流，Chisel 提供了 DecoupledIO 用以实现这一协议。然而，DecoupledIO 仅是一个预置的 Bundle，缺少与之配套的一系列常用组件（例如寄存器切片、Mux/Demux 等），此外它也未能搭配 chipmunk.IsMasterSlave。chipmunk 为 DecoupledIO 提供了一个“威力加强版”的 Ready/Valid 握手协议——chipmunk.StreamIO。 Ready/Valid 握手协议 Ready/Valid 握手协议由三部分信号组成： valid：表示数据有效，即上游数据已经准备好，可以被消费； ready：表示数据可被消费，即下游已经准备好接收数据； bits（即 payload）：表示数据本身。 其中，valid 和 bits 信号由上游产生，ready 信号由下游产生。当 valid 和 ready 信号同时有效时，bits 信号被传递，即数据被消费。利用这一协议，我们可以将数据流的生产和消费解耦：上游模块只需要在准备好数据后将 valid 和 bits 信号置为有效，而无需关心下游模块内部的状态；而下游模块只需要在准备好接收数据后将 ready 信号置为有效，当 valid 和 ready 信号同时有效时取走 bits 数据。通过使用 Ready/Valid 握手协议，开发者可以将注意力集中在自己负责的电路逻辑上，而无需过度关心其他模块的内部实现，从而提高开发效率。 需要注意的是，为了避免组合逻辑环路，我们要求 valid（及 bits）和 ready 信号不能同时依赖对方的当前状态。因此，在 Chipmunk（和其他绝大多数数字电路设计）中，我们约定 valid 不允许依赖于 ready 的当前状态，即上游模块不允许根据下游模块此刻是否 ready 来决定当前周期是否将 valid 置为有效。简单地说，用于 valid 产生的组合逻辑表达式中不能出现下游模块的 ready 信号。 关于 Ready/Valid 握手协议的更多细节，网上已经有了丰富的材料可以参考，这里不再赘述。 关于 StreamIOWhy?Chisel 提供了 DecoupledIO 和 IrrevocableIO 两个 Ready/Valid 握手协议的 Bundle 实现，它们都继承自 chisel3.ReadyValidIO。Chisel 并未为这两个接口提供太多 API，基本上只有： def fire: Bool = ready &amp;&amp; valid，表示当前周期是否发生了数据传输； class Queue，以 ReadyValidIO 为接口的同步 FIFO； def map[T](f: T =&gt; T2): T，用于对 bits 进行变换。 IrrevocableIO 其实在实现上 DecoupledIO 并无区别，只是约定它的 bits 在 valid 有效但 ready 无效时不会改变，即数据不可撤回。两者的实际差别有赖于具体模块中的电路实现。 很显然，上述 API 不足以应付实际的设计需求。 Chipmunk 在 chisel3.ReadyValidIO 的基础上提供了 chipmunk.StreamIO，它继承自 chisel3.ReadyValidIO，并提供了一系列常用的 API 和特性，包括： 一系列类似fire 的语法糖，展现数据传输的不同状态； 符号化的连接方法，类似 a &gt;&gt; b &gt;-&gt; c，可以很容易地看出数据的流向； 针对 bits 的一系列操作，包括 Map、Cast 等； 一系列常用的组件，包括寄存器切片（Register Slice）、Fork/Join、Mux/Demux 等。 StreamIO 在实现上参考了 SpinalHDL 的 Stream 的 API 设计，熟悉 SpinalHDL 的同学应该会有一丝熟悉的感觉。 UsageStreamIO 例化 创建一个 StreamIO，其 payload 类型为 UInt： Code Snippet1val myStream = Wire(Stream(UInt(32.W))) 创建一个 StreamIO，其 payload 类型和另一个 DecoupledIO 的 bits 一致： Code Snippet12val myDecoupled = Wire(Decoupled(UInt(32.W)))val myStream = Wire(Stream(myDecoupled)) 请注意这里 myStream 不会与 myDecoupled 有任何电路连接（比如共享 bits），而是会创建一个新的 UInt 作为 payload。 创建一个空的 StreamIO（即其 payload 类型为 EmptyBundle）： Code Snippet1val myStream = Wire(Stream.empty) 空的 StreamIO 一般用于声明时没有确定 payload 类型的情况，后续可以搭配 payloadReplace 等 API 赋予具体的 payload。 流控与状态指示StreamIO 提供以下状态指示方法，它们的返回类型均为 Bool： 语法 描述 x.fire 当前周期正在进行数据传输，即 ready &amp;&amp; valid x.isPending 上游数据已经就绪，但下游未能准备好接收，即 !ready &amp;&amp; valid x.isStarving 下游已准备好接收数据，但上游没有发起传输，即 ready &amp;&amp; !valid StreamIO 也提供下列方法对数据流进行流控，它们会返回一个新的 StreamIO： 语法 描述 x.haltWhen(cond) 当 cond 为 True 时，数据传输会被阻断，即上下游模块均无法完成握手。 x.continueWhen(cond) 相当于 x.haltWhen(!cond) x.throwWhen(cond) 当 cond 为 True 时，数据传输会被丢弃，即上游模块发起的数据传输都会成功握手，但下游模块不会收到相应的数据。 x.takeWhen(cond) 相当于 x.throwWhen(!cond) Payload 变换 StreamIO 允许对 payload 直接进行一系列变换，包括： Code Snippet123def payloadMap[T2 &lt;: Data](f: T =&gt; T2): StreamIO[T2]def payloadReplace[T2 &lt;: Data](p: T2): StreamIO[T2]def payloadCast[T2 &lt;: Data](gen: T2, checkWidth: Boolean = false): StreamIO[T2] 上述方法会返回一个新的 StreamIO，其 payload 会变成变换后、类型为 T2 的新信号，同时其 ready 和 valid 信号会连接到当前 StreamIO 的 ready 和 valid 信号。 payloadMap 可以将函数 f 作用于 payload，比如： Code Snippet12val streamOld = Wire(Stream(UInt(32.W)))val StreamNew = streamOld.payloadMap(_ + 1.U) payloadReplace 会将 payload 替换为 p，相当于 payloadMap(_ =&gt; p)，比如： Code Snippet123val streamOld = Wire(Stream(UInt(32.W)))val anotherBool = Wire(Bool())val StreamNew = streamOld.payloadReplace(anotherBool) payloadCast 会对 payload 进行强制类型转换，相当于 payloadMap(_.asTypeOf(gen))，比如： Code Snippet12val streamOld = Wire(Stream(UInt(32.W)))val StreamNew = streamOld.payloadCast(SInt(32.W), checkWidth = true) 其中参数 checkWidth = true 允许检查类型转换前后的位宽是否一致，如果不一致抛出异常。该参数默认为 false，即不会检查位宽，如果位宽不一致会自动截断或扩展。 寄存器切片（Register Slice）为 StreamIO 插入寄存器切片以改善时序，是一个常见的需求。然而，这实现起来非常繁琐且易错。显然，我们不能直接在 StreamIO 的 ready/valid/bits 路径上贸然插入寄存器切片。valid 和 ready 分别代表当前周期上游模块和下游模块的状态，在它们的传播通路上引入寄存器会导致状态延后若干周期才会传播到对侧。这会导致上下游模块无法在正确的时机完成握手，可能会引起数据丢失或吞吐下降。 根据寄存器插入位置不同，StreamIO 提供： pipeForward：前向寄存器切片，切断从上游模块到下游模块的 valid 和 bits 通路的组合逻辑路径；Code Snippet1val streamNew = streamOld.pipeForward() 它在性能上不会引入吞吐下降（虽然会增加 1 周期延时），在面积上代价是 N + 1 个寄存器（N 是 bits 位宽）以及少量组合逻辑。 pipeBackward：后向寄存器切片，切断从下游模块到上游模块的 ready 通路的组合逻辑路径。Code Snippet1val streamNew = streamOld.pipeBackward() 它在性能上不会引入额外的延时和吞吐下降，在面积上代价是 N + 1 个寄存器（N 是 bits 位宽）、N 个 2:1 MUX 以及少量组合逻辑。 pipeAll：双向寄存器切片，同时切断 valid、bits、ready 通路的组合逻辑路径。Code Snippet1val streamNew = streamOld.pipeAll() 相当于 streamOld.pipeForward().pipeBackward()，因此它会引入 2N + 2 个寄存器（N 是 bits 位宽）、N 个 2:1 MUX 以及少量组合逻辑。 pipeSimple：双向寄存器切片，同时切断 valid、bits、ready 通路的组合逻辑路径。Code Snippet1val streamNew = streamOld.pipeSimple() 它至多每隔一个周期握手一次，因此会引起最高可达一半的吞吐损失，但面积上只需要 N + 2 个寄存器以及少量的组合逻辑。与 pipeAll 相比，它的面积代价更小，但会引入额外的性能损失。 pipeValid：仅切断 valid 通路的组合逻辑路径。Code Snippet1val streamNew = streamOld.pipeValid() 面积上仅需要 1 个寄存器和少量组合逻辑。 pipPassThrough：什么都不做，返回当前的 StreamIO。Code Snippet1val streamNew = streamOld.pipPassThrough() 符号化连接StreamIO 提供了一系列方法用于连接其他 StreamIO： 语法 描述 x.connectFrom(y) 用 y 驱动 x，即 y 作为 x 的上游进行连接 ready、valid、bits 信号 x.handshakeFrom(y) 和 connectFrom 类似，但只连接 ready、valid 信号，不连接 bits 信号 x &lt;&lt; y 相当于 x.connectFrom(y)，返回 y x &gt;&gt; y 相当于 y.connectFrom(x)，返回 y x &lt;-&lt; y 相当于 x &lt;&lt; y.pipeForward()，返回 y x &gt;-&gt; y 相当于 x.pipeForward() &gt;&gt; y，返回 y x &lt;|&lt; y 相当于 x &lt;&lt; y.pipeBackward()，返回 y x &gt;|&gt; y 相当于 x.pipeBackward() &gt;&gt; y，返回 y x &lt;+&lt; y 相当于 x &lt;&lt; y.pipeAll()，返回 y x &gt;+&gt; y 相当于 x.pipeAll() &gt;&gt; y，返回 y 借助 &lt;&lt;、&gt;&gt; 等流操作符，我们可以实现可读性较强的 StreamIO 连接甚至级连，比如： Code Snippet123val s1 = Stream(UInt(8.W))s1 &lt;-&lt; uAnotherModule.io.outStreams1.haltWhen(somethingEnable) &gt;&gt; uSomeModule.io.inStream 配套组件Chipmunk 包括了一系列 StreamIO 的配套组件。 StreamFork/StreamJoinStreamFork 可以将一个上游 StreamIO 分叉成多个下游 StreamIO，每个下游 StreamIO 会分别完成仅一次握手，上游 StreamIO 会在所有下游 StreamIO 完成握手后才完成握手。为了提高性能，每个下游 StreamIO 是否握手是独立进行的，当它 ready 有效时即完成握手，而不需要等到所有下游 StreamIO 的 ready 都有效。 StreamJoin 可以将多个上游 StreamIO 合并成一个下游 StreamIO，当且仅当所有上游 StreamIO 的 valid 都有效时，才会发生握手。 在 object StreamFork/object StreamJoin 中，Chipmunk 提供了多个接口略有差别的方法。用户可以阅读代码中的注释，根据自己的需求选择合适的方法。 StreamMux/Demux/…TODO See Also Chipmunk Github photoed by Annegret Kammer","link":"/Engineering/chipmunk-stream/"},{"title":"SSH 通过 443 端口连接 GitHub","text":"GitHub 提供了两种协议供用户使用 Git 连接—— SSH 和 HTTPS。理论上我可以随意选择两者之一连接到我在 GitHub 上的代码仓库，无论是将云端的仓库 clone 到本地，还是将本地的修改 push 到云端。然而，出于一些奇奇怪怪的原因，我所在的办公网络环境禁止了 22 端口，而 22 端口正是 GitHub 提供 SSH 访问的端口号。尽管可以换用 HTTPS 协议，但无论如何将我电脑上的所有代码仓库的上游都从 git@github.com:... 修改称 https://github.com/... 仍然是一个繁重的体力活。 为了一劳永逸地解决这个问题，最理想的解决方式是让 Git 的 SSH 协议改用 22 以外的其他端口连接 GitHub。 SSH 连接失败我们在 clone GitHub 上的代码仓库时，可以看到 GitHub 提供了两种不同的链接（以我的 SpinalHDL 模版仓库为例）： Terminal12git clone https://github.com/zhutmost/spinalhdl-template.git # HTTPSgit clone git@github.com:zhutmost/spinalhdl-template.git # SSH 其中第一种方式，即 HTTPS 协议，一般总能可以工作（只要能在浏览器里打开 GitHub），而后者依赖 SSH 的正常工作。因为我的网络环境阻断了 22 端口的连接，所以我测试 GitHub 的 SSH 连接时会出现以下报错： Terminal123❯ ssh -T git@github.comkex_exchange_identification: Connection closed by remote hostConnection closed by xx.xx.xx.xx port 22 而在理想情况下，上述命令应当输出： Terminal12❯ ssh -T git@github.comHi zhutmost! You've successfully authenticated, but GitHub does not provide shell access. 奇妙的冒名顶替仔细发掘GitHub的文档，可以发现 GitHub 在另一个域名（ssh.github.com）上提供了一个 443 端口的 SSH 服务。显然，防火墙一般不会阻拦 443 端口（只要能浏览 GitHub 网站就能连上），可以用下面的命令进行测试： Terminal1❯ ssh -T -p 443 git@ssh.github.com 为了让Git也能通过上述端口用 SSH 访问 GitHub，我们为上述 SSH 连接方式设置一个别名。首先找到SSH的配置文件，它的路径一般是~/.ssh/config，如果这个文件不存在的话也可以创建一个。然后，在其中增加以下内容： ssh_config1234Host github.com HostName ssh.github.com User git Port 443 其中，Host 是别名，HostName 是实际的域名地址，Port 是端口号。因为我希望当我在用 SSH 连接 github.com 时，实际访问的是 ssh.github.com，所以 Host 和 HostName 分别设置成这两个域名（注意不要颠倒顺序）。 如此一来，ssh.github.com 就成为了 github.com 的“冒名顶替”者。当 Git 通过 SSH 协议试图访问 github.com 的时候，SSH 会发现它是 ssh.github.com 的别名，因此会用 443 端口实际连接到后者。这样，就绕开了本地网路环境对 22 端口的限制。 （我之所以使用上述方法，是因为我的网络情况比较复杂。建议公司的朋友在使用暗渡陈仓之策前，先和 IT 部门确认下是否合规。） Thumbnail by Besthqwallpapers","link":"/Engineering/github-ssh-443/"},{"title":"EdgeBoard的PYNQ移植","text":"PYNQ是我很喜欢的一个FPGA开源工具。它将Zynq上的各种硬件资源用Python封装了起来，允许用户通过Jupytor Notebook远程调试FPGA。将PYNQ移植到Baidu EdgeBoard上是我去年在COVID疫情期间开的坑（具体请参看我的GitHub），但中间遇到的小问题有点多，便一直没有完全填上。我最近抽出了些时间重新拾起了这个事情，就顺便把整个过程和遇到的问题都记录下来，以飨后来者。 相关源代码已开源至Github，预编译PYNQ镜像文件我也已上传至阿里云盘。因为设备有限，我没有为这个镜像进行所有外设的上板测试。如果你发现了任何问题，欢迎和我联系。 PYNQ官方提供了SD卡镜像编译的文档，因此一些比较明确的步骤我可能不会详述，请搭配官方文档阅读。 为了避免混淆，这里先澄清一下很多朋友的一个小误解：本文中的PYNQ指的是PYNQ框架（本质上是一个Ubuntu），而非那两个粉色的开发板（PYNQ-Z1和PYNQ-Z2）。PYNQ可以部署在PYNQ-Z1和PYNQ-Z2上，也可以部署在其他Zynq系列的FPGA上。 开始之前Xilinx提供了PYNQ-Z1、PYNQ-Z2、ZCU104等开发板的镜像，可以直接从PYNQ网站上下载到，具体列表可以在PYNQ的下载页面找到（也包括Ultra96等第三方开发板）。如果我们想要在此外的开发板（比如本文中的EdgeBoard Lite）上使用PYNQ，就需要自己编译PYNQ镜像。 本文的编译目标是PYNQ v2.7。本文写作时（2021年8月）PYNQ2.7的开发已经完成，但是还没有合入主线分支，文档也没有更新（但差别不大，反正各种奇奇怪怪的bug本来也不会写在文档里）。每次大版本（即2.X）更新后，随着时间推移，依赖软件包之间会出现五花八门的兼容性问题，这些问题很可能要到下一次PYNQ大版本更新才会一次性修复。这个问题主要得归咎于Xilinx官方，PYNQ的编译中依赖的很多软件都不指定特定版本。因此，如果你看到本文时已是很久之后，文章中遇到的问题和你遇到的可能不尽相同。 硬件上，除了Edgeboard本身，我准备了一台半淘汰的笔记本搭建编译环境。这个不是很重要（虚拟机也不是不可以），唯一需要确认的是剩余磁盘空间要够大（大约200GB）。 PYNQ v2.7需要Vivado/Vitis/PetaLinux的版本为2020.2。我的操作系统是Ubuntu 18.04.5 LTS。Vivado/Vitis 2020.2最高支持Ubuntu 18.04.4，安装时需要修改/etc/os-release骗过安装程序。这里操作系统的版本建议请严格按照Xilinx的安装指南，我不建议你和我一样操作。 编译过程中需要从互联网上下载大量依赖组件，请确保你能够自由访问互联网。 理想的编译过程设置PYNQ环境首先将PYNQ的GitHub Repo复制到本地，并切换到image_v2.7分支。 Terminal123❯ git clone https://github.com/Xilinx/PYNQ.git pynq❯ cd pynq❯ git checkout image_v2.7 我们接下来的主要工作都在sdbuild目录下进行。先运行scripts/setup_host.sh，它会用apt安装各种需要的包，以及下载QEMU和CrossTool-NG。 Terminal1❯ source ./scripts/setup_host.sh 这个脚本运行需要很久的时间（主要是因为下载QEMU和CrossTool-NG的安装包），但好在只需要运行一次。 后续编译过程还会依赖Ninja，然而该脚本中没有安装，因此我们手动安装下。 Terminal1sudo apt install ninja-build 到这里，Xilinx全家桶需要的各种依赖包也安装完成了，接下来就可以安装Xilinx全家桶了。 安装Xilinx全家桶我们需要安装Vivado、Vitis、PetaLinux三个软件。按照PYNQ v2.7的版本要求，三者的版本都必须是2020.2。这里需要注意的是，不要使用管理员权限安装。 Vivado和Vitis是通过同一个安装程序安装的，安装时命令行运行./xsetup，勾选需要的组件即可。 PetaLinux安装的命令如下： Terminal1❯ petalinux-v2020.2-final-installer.run --dir &lt;xilinx_install_dir&gt;/petalinux/2020.2 --platform &quot;aarch64 arm&quot; 具体安装选项可以参考UG1144。这里存在一个坑，PetaLinux的安装程序允许用户任意指定安装位置，但是PYNQ之前的版本默认却要求它的路径必须是.../2020.2/的形式（v2.7有无修复不确定，我没有去测试）。 安装完成后，我们需要将下面几行代码加入.bashrc（也可以每次打开命令行手动执行）。这样一来，就可以在命令行中运行这些软件了。 .bashrc123source &lt;xilinx_install_dir&gt;/petalinux/2020.2/settings.shsource &lt;xilinx_install_dir&gt;/Vivado/2020.2/settings64.shsource &lt;xilinx_install_dir&gt;/Vitis/2020.2/settings64.sh 添加自定义开发板PYNQ在boards文件夹下预置了Pynq-Z1、Pynq-Z2、ZCU104三个与对应开发板同名的文件夹。它们的内部结构大同小异，主要分成以下五个部分： notebooks； petalinux_bsp； packages； base、logictools等Overlay文件夹； &lt;board_name&gt;.spec。 下面简单介绍下这些文件和文件夹的功能，具体的细节（如果你需要定制一些复杂的东西）还请自行阅读PYNQ的编译脚本源代码。 notebooks文件夹会原样复制到最终的用户目录下，每次大家打开Jupyter Notebook后看到的就是它。这个文件夹里的内容不是很重要，一般都是放些教程。 petalinux_bsp文件夹用于PetaLinux生成BSP，它只在sdbuild/scripts/create_bsp.sh脚本中用到。该文件夹里边包括两个文件夹meta-user、hardware_project。其中，meta-user文件夹会被复制到PetaLinux项目文件夹下的project-spec/meta-user，里面放设备树文件、各种用户配置等（如果你对PetaLinux项目的目录结构不了解的话可以参考UG1144）。hardware_project里需要放.xsa硬件描述文件（该文件由Vivado导出），或者也可以放一些脚本（至少包括一个Makefile）供PetaLinux实时地生成.xsa文件。如果用户在&lt;board_name&gt;.spec中指定了BSP，那么hardware_project不会被用到。这里一个文档中一个没有注明的是，meta-user总是会起作用，即使你指定了BSP，它也会覆盖掉里边的meta-user并重新打包。 packages文件夹的结构和sdbuild/packages的结构类似，这两个目录下的每个文件夹对应一个个的组件，在编译过程中会被安装到RootFS中。安装过程主要是在sdbuild/scripts/install_packages.sh中进行。如果你需要增加组件，建议阅读此脚本和sdbuild/packages/README.md了解更多细节。 其他文件夹中如果存在Makefile文件，就会被认为是Overlay文件夹。在编译pynq本身时，&lt;pynq_repo_dir&gt;/build.sh脚本会试图进入这些文件夹，并挨个检查是否存在.bit、.hwh、.xsa等文件。这些文件夹不是必须的，主要是为用户提供一些针对该开发板的预置Overlay。 &lt;board_name&gt;.spec文件描述了针对该开发板的各种配置和文件路径。它的格式如下所示： board_name.spec123456ARCH_&lt;board_name&gt; := aarch64 # Zynq的CPU架构，可以是aarch64或armBSP_&lt;board_name&gt; := ... # 开发板的BSP文件（如果有的话）BITSTREAM_&lt;board_name&gt; := ... # 默认的比特流文件FPGA_MANAGER_&lt;board_name&gt; := 1STAGE4_PACKAGES_&lt;board_name&gt; := pynq ethernet ... 注意这里的board_name要和文件夹的名字一致。 接下来我们可以依样画葫芦为自己的开发板配置这些文件了。我在edgeboard的仓库中放置了针对EdgeBoard Lite的配置文件，如果需要的话你也可以参考。 一把梭编译，赌人品按照官方的流程，理论上我们可以开始进行漫长的编译了。不过我强烈建议你先阅读下后续的几个章节再开始编译（可以避免很多无谓的时间浪费）。 在sdbuild下运行： Terminal1❯ make BOARDDIR=&lt;edgeboard_repo_dir&gt;/edgeboard/pynq BOARDS=edgeboard-fz3a 运气不错的话，我们能够在几个小时后获得最终的SD卡镜像edgeboard-fz3a-2.7.0.img，然后就可以将其烧写到SD卡上了。 Terminal1❯ sudo dd if=&lt;pynq_repo_dir&gt;/sdbuild/output/edgeboard-fz3a-2.7.0.img bs=1M of=/dev/mmcblk0 &amp;&amp; sync 注意这里你的SD卡设备名可能不是/dev/mmcblk0，请务必再三确认，以免写入其他磁盘丢失数据。 各种常见和不常见的Bug实践中，上一步十之八九会遇到各种奇奇怪怪的问题，然后报错退出。这里我没法给出一个万能方法，只能说“具体情况，具体分析”。记得多翻日志，多问谷歌。 我把各种我遇到的问题罗列于此，并提供了我的原因分析和解决方法。 NodeJS安装时报错base_files is not configured在运行到sdbuild/packages/jupyter/qemu.sh时，它会用apt安装NodeJS（这是运行Jupyter Notebook必要的）。此时，apt安装无法完成，并出现以下报错： Terminal123456789101112131415Setting up base-files (11ubuntu5) .../bin/rmdir: failed to remove '/var/run': Directory not emptydpkg: error processing package base-files (--configure): installed base-files package post-installation script subprocess returned error exit status 1dpkg: dependency problems prevent configuration of bash: bash depends on base-files (&gt;= 2.1.12); however: Package base-files is not configured yet.dpkg: error processing package bash (--configure): dependency problems - leaving unconfiguredErrors were encountered while processing: base-files bashNo apport report written because the error message indicates its a followup error from a previous failure.E: Sub-process /usr/bin/dpkg returned an error code (1) 它提示NodeJS在安装时需要访问一个名为base-files的组件，但是该组件在此时还没有完成“configure”。我们沿着这个信息往上追溯的话，会一直找到RootFS的初始化，此时该组件应当完成安装。 PYNQ采用Multistrap作为RootFS的初始化工具，它利用apt下载所需要的包并进行安装。base-files正是其中一个此时应当被安装的包，完整的包列表可以见ubuntu/focal/aarch64/multistrap.config。观察安装日志，可以最终定位到真正的错误原因：base-files的安装会用到chmod，这要求另一个名为base-passwd的包必须比它先完成“configure”，否则base-files的安装就会失败。简而言之，就是base-files依赖base-passwd。 那么问题来了，为什么RootFS初始化时部分包安装失败后不会报错呢？原因在sdbuild/scripts/create_rootfs.sh脚本中如下的两行代码抑制了postinst1.sh和postinst2.sh两个脚本的报错： create_rootfs.sh123$dry_run sudo -E chroot $target bash postinst1.sh... # other stuff$dry_run sudo -E chroot $target bash postinst2.sh 因此此处即使发生安装失败，程序也会继续执行下去。 更为本质的一个问题是为什么dpkg无法检测到上述两个软件包之间的依赖关系。这已经超出了PYNQ的范畴，根据Debian社区的意思大体上可以这么理解：base-files和base-passwd都是属于Essential的包，理论上它们都是必装的，因此就没有设置依赖关系。如果我们为这些必装的组件之间相互设置依赖关系的话，会陷入循环依赖的地狱。那么在安装时它们之间发生依赖冲突怎么办呢？这个问题至少在2011年就有人提出过，社区的结论是这个问题并不常见（多数时候base-passwd总比base-files先完成“configure”），所以不妨依靠玄学。他们认为这个问题在新的Multistrap版本上不会出现，然而并不。 这里我的解决方法是手工指定dpkg --configure的顺序，将sdbuild/scripts/create_rootfs.sh的postinst1.sh部分中原先的dpkg --configure -a修改成： create_rootfs.sh1234# 先完成base-passwd的configuredpkg --configure gcc-10-base libcrypt1 libc6 libgcc-s1 libdebconfclient0 base-passwd# 再完成其他组件的configuredpkg --configure -a python2.7-minimal安装失败与上个问题类似，有时会出现python2.7-minimal这个包的configure失败。这个问题本身不是很严重，因为postinst1.sh和postinst2.sh两个脚本会各执行一遍dpkg --configure -a，因此第一遍中极少量没成功安装的包会在第二遍中完成安装（比如cups-pk-helper这个包经常如此）。然而，因为有大量包依赖于python2.7-minimal，一旦它安装失败后，一连串的包会一同安装失败，然后安装程序就崩了。 这里可以从报错信息中观察到，安装失败的原因是它的postinst脚本中用到了awk，然而此时awk这个命令还未安装。解决方法也和上个问题类似，即手工指定dpkg --configure的顺序，确保提供awk命令的包比python2.7-minimal先完成configure。有很多包都提供了awk命令，我这里选择了mawk。 create_rootfs.sh12dpkg --configure &lt;... 其他需要提前`configure`的包&gt; mawkdpkg --configure -a 无法从SD卡启动，找不到RootFS这个问题深究起来非常复杂，现象是烧写完SD卡上板卡后，无法完成开机，屏幕/串口会显示内核错误。其中括号里的数字我这边是179,2和179,10两种情形之一（我没有彻底弄清楚这俩数字的含义）。 1Kernel Panic - not syncing: VFS: Unable to mount root fs on unknown-block(179,10) 关于SD卡的一系列bug都会引起这个报错。首先请确保SD卡烧写成功，烧写完成后可以在Ubuntu中挂载并尝试打开检查一下，如果不能正常打开的话重新烧写下。然后请参考以下几点依次排查。因为该报错的原因很多，我这里可能列举不全，见谅。 使用dd烧写时块大小不合适RootFS分区的文件系统是Ext4，它在开机时会检查分区大小，因此如果在dd时使用过大的块大小（block size，也就是bs=...参数），就会无法通过分区大小的检查。 比如用4M的块大小烧写镜像的话（即sudo dd bs=4M if=... of=...），开机就会保错。在我这使用1M的块大小是正常的，具体命令可以看前文。 SD卡的写保护这个问题似乎是来自于很多人使用了淘宝购买EdgeBoard FZ3A开发板时店家提供的所谓“Vivado参考设计”。这个参考设计中关于SD卡的配置存在错误，它打开了SD卡槽的写保护引脚。但是据WhyCan Forum社区的文章指出，EdgeBoard的PCB设计中去掉了这一引脚。因此，我们稳妥起见，可以在设备树中禁用掉写保护功能。 如前文所述，PYNQ为我们提供了一个修改设备树的接口，就是boards/&lt;board_name&gt;/petalinux_bsp文件夹。我们先在相应目录下创建一个设备树文件： Terminal123❯ mkdir -p &lt;pynq_repo_dir&gt;/boards/&lt;board_name&gt;/petalinux_bsp/meta-user/recipes-bsp/device-tree/files❯ cd &lt;pynq_repo_dir&gt;/boards/&lt;board_name&gt;/petalinux_bsp/meta-user/recipes-bsp/device-tree/files❯ touch system-user.dtsi 然后对sdhci1节点（对应于PS_SD1，即我们的SD卡槽）进行修改。完成以后，你的system-user.dtsi文件应该长这个样子： system-user.dtsi12345678910/include/ &quot;system-conf.dtsi&quot;/ { /*根节点，这里保持不变*/};&amp;sdhci1 { status = &quot;okay&quot;; max-frequency = &lt;50000000&gt;; no-1-8-v; /*我其实不太理解这行的作用，但反正一出兼容性问题，大家就会写这个*/ disable-wp; /*关掉写保护功能*/} 理论上如果使用我自己做的Board Files里的Zynq Preset，是不会遇到这个问题的（不过我没试，重新编译太费时了）。 Boot参数中设置了错误的root分区位置PYNQ默认总是从/dev/mmcblk0（这个路径是PYNQ上的，不是你的宿主Ubuntu上的）启动系统，即它如果它有多个SD外设的话，SD卡要连在PS_SD0上。不幸的是，EdgeBoard还真的有两个SD设备，一个是我们的TF卡槽，另一个是一颗eMMC Flash芯片。默认情形下，PYNQ总是会尝试从后者启动，而我们的系统实际存放在SD卡上。 PetaLinux的Boot参数是通过设备树中的/chosen/bootargs条目进行配置的。默认情况下，最后镜像使用的设备树中该条目会是这样的（每个字段的先后顺序不重要）： system-user.dtsi1bootargs = &quot;root=/dev/mmcblk0p2 rw earlyprintk rootfstype=ext4 rootwait devtmpfs.mount=1 uio_pdrv_genirq.of_id=\\&quot;generic-uio\\&quot; clk_ignore_unused&quot;; 但我们希望其中的字段root=/dev/mmcblk0p2变成root=/dev/mmcblk1p2。直觉上，首先想到的是很上文一样修改system-user.dtsi文件，从而影响最终生成的设备树。实验会告诉你完全不起作用，最后输出也就是实际使用的设备树里还是上面这行默认值。这里大家就会遇到PYNQ这个编译流程设计的很糟糕的一点：system-user.dtsi这个文件中的只有一部分会起作用，至于想弄清哪部分，要么做实验，要么看懂编译源代码。比如上面对&amp;sdhci1节点的修改就能生效，对/chosen/bootargs对修改就不起作用。 生成设备树是制作BSP文件的中一部分，接下来我们来弄清楚PYNQ是如何生成最终的BSP文件的。我们先考虑用户没有提供预编译的BSP文件的情形，此时PYNQ内部会依次做这些事： 建立一个空的PetaLinux项目 拷贝用户的petalinux_bsp/meta-user到该项目下； 读入硬件配置即petalinux_bsp/hardware_project中的XSA文件，生成Config文件； 构建并打包成BSP文件； 利用上一步获得的BSP文件建立一个新的PetaLinux项目； 直接在脚本中修改Config文件，加入一些配置； 重新运行petalinux-config生成新的Config文件； 开始各种build，最终生成我们需要的BOOT.bin。 其中步骤1、2、3、4在sdbuild/scripts/create_bsp.sh脚本中进行，步骤5、6、7、8在sdbuild/Makefile中进行。如果用户指定了预编译的BSP文件，就把上文中的第1步换成“利用用户提供的BSP文件建立一个新的PetaLinux项目”。这里最令人困惑的地方是，为什么要进行两次“create-config-build”的流程，至少我没有看出它这么做的必要性。这样一通操作之后，用户在petalinux_bsp/meta-user的子目录下的system-user.dtsi文件中修改的一些设备树节点（对应上文步骤2），会在步骤6中被新引入的一些设备树文件冲刷掉。步骤6通过CONFIG_USER_LAYER_0这一设置混入了一些新的设备树文件，这些额外的设备树文件位于sdbuild/boot/meta-pynq/recipes-bsp/device-tree。就Boot参数而言，这里边的pynq_bootargs.dtsi文件提供了前述的默认/chosen/bootargs。因此无论我们在system-user.dtsi文件中如何修改/chosen/bootargs，最终都会被覆盖掉。因此，我们的解决方案很简单，修改下该文件，将其中的root=/dev/mmcblk0p2变成root=/dev/mmcblk1p2。因为这个文件只有几行，改动也很小，我就不把代码贴出来了。 除了修改pynq_bootargs.dtsi，我们还需要修改sdbuild/Makefile，将下面这行代码中的mmcblk0p2变成mmcblk1p2。 Makefile1echo 'CONFIG_SUBSYSTEM_SDROOT_DEV=&quot;/dev/mmcblk0p2&quot;' &gt;&gt; $$(PL_CONFIG_$1) 我这里提供另一个有趣的思路，sdhci0和sdhci1在设备树文件中是俩alias，我们可以在设备树中交换它们的值（/amba/mmc@ff160000和/amba/mmc@ff170000）。不过我没有做过实验。 UART串口不工作EdgeBoard FZ3A有两个UART串口，一个是BT1120连接件的一部分，另一个转成了USB接口。我们用来连接电脑进行交互的串口，显然希望是后者。和前面SD卡的情况相似，PYNQ默认PS_UART0作为输出串口，而我们实际想要的是PS_UART1。解决这个问题的方法很简单，在上面修改CONFIG_SUBSYSTEM_SDROOT_DEV的那行后面加上以下几行： Makefile12345echo 'CONFIG_SUBSYSTEM_PMUFW_SERIAL_PSU_UART_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1)echo 'CONFIG_SUBSYSTEM_FSBL_SERIAL_PSU_UART_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1)echo 'CONFIG_SUBSYSTEM_ATF_SERIAL_PSU_UART_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1)echo 'CONFIG_SUBSYSTEM_SERIAL_PSU_UART_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1)echo 'CONFIG_SUBSYSTEM_PRIMARY_SD_PSU_SD_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1) dash.preinst找不到RootFS的编译脚本（即create_rootfs.sh）会在前面提到的postinst1.sh和postinst2.sh两个脚本执行中提示dash.preinst执行失败，原因是/var/lib/dpkg/info/dash.preinst找不到。该错误的原因仅仅是上游已经把dash.preinst这个脚本删除了（可参考此文）。因此这里执行该脚本的三行代码都是多余的，直接删除即可。即使不删除，它们也应当不会引起其他异常（除了在终端里输出一些错误信息）。 RootFS分区磁盘容量不足PYNQ在编译的最后，会对最终的镜像的RootFS分区进行扩容。扩容主要是增加一些用户空间，以及给操作系统本身腾出一些地方放临时文件。扩容操作是在sdbuild/scripts/resize_umount.sh脚本中进行（别问我为什么文件名中unmount拼写错了，源代码如此）。PYNQ的开发者很可能是为了尽量使最终镜像小于8GB，所以只额外扩容了300MB。 很不幸的是，这300MB实在是捉襟见肘，经常开完机就用得七七八八了。极端情况下，可能不足以支撑Jupyter成功运行，现象是能够ssh访问，但浏览器完全打不开Jupyter。排查方法是，上电后通过ssh进入板上的操作系统，执行df，观察/分区的磁盘占用情况。 我的SD卡是64GB的，因此，我直接修改了resize_umount.sh脚本，将扩容空间从300MB改成了3000MB。你可以根据你的SD卡容量自由发挥，当然没必要太大，否则烧写SD卡会变得很慢。具体到代码上，在该脚本中找到下面一行代码，把其中的300改成任意你想要的数字。 Makefile1new_size=$(( $used_size + (300 * 1024) )) 各种文件下载失败多数都是网络环境的问题，可以先阅读下一节。如果还是解决不了的话，请联系公司的IT工程师协助解决。 Speedup！编译提速在我的破笔记本上，完整的一次PYNQ流程需要整一个下午，中间还需要多次输入管理员密码。因为我们很难一次成功，所以需要不断地重新进行编译流程，所以我们总希望整个编译能够进行地快一些。接下来我们开始着手加速编译流程。 跳过输入管理员密码PYNQ编译中会频繁使用sudo命令，需要我们不断地输入密码，否则程序就一直卡在那等待。Ubuntu默认两次sudo的时间间隔超过15分钟左右就要重新输入密码，我们可以把这个时间延长一些（比如这里我延长到了2小时）。 首先在/etc/sudoers中找到如下一行。 1Defaults env_reset 将它改成： 1Defaults env_reset,timestamp_timeout=120 为Multistrap更换下载源Multistrap利用apt下载各种需要的包来构建RootFS。默认情况下，apt会从官方ports源（http://ports.ubuntu.com/ubuntu-ports）下载文件，时间很长且经常失败。换源的方法非常方便，直接在编译开始前声明PYNQ_UBUNTU_REPO环境变量即可。例如换成清华源： Terminal1❯ export PYNQ_UBUNTU_REPO=http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports 注意这里必须是http而不是https。 为CrossTool-NG建立本地缓存CrossTool-NG每次运行时会从云端下载很多包（主要是各种源代码）。根据其文档的指示，我们可以建立一个本地的缓存文件夹。当需要下载的包本地已经缓存时，它就会跳过下载，从而节省时间。CrossTool-NG的配置文件在sdbuild/packages/gcc-mb/samples/&lt;compile_targets&gt;/crosstool.config，在其最后加上两行： crosstool.config12CT_SAVE_TARBALLS=yCT_LOCAL_TARBALLS_DIR=&lt;somewhere_to_put_downloaded_files&gt; 注意请在运行前保证该路径是个文件夹，且具有读写权限。 为PetaLinux建立本地SSTATE缓存首先去Xilinx官网下载sstate-cache文件。注意版本要和PetaLinux保持一致（本文中我们用的是2020.2）。 因为EdgeBoard FZ3A板载的Zynq芯片是ARM64架构，因此为了节约空间，就只下载“aarch64 sstate-cache”和“downloads”两个包（加起来也超过60GB了）。然后我们将它们解压缩，并把路径添加到petalinux_bsp/meta-user/conf/petalinuxbsp.conf： petalinuxbsp.conf12DL_DIR = &quot;&lt;sstate_extract_dir&gt;/2020.2/downloads&quot;SSTATE_DIR = &quot;&lt;sstate_extract_dir&gt;/2020.2/sstate-cache/aarch64&quot; 删除boards目录下Pynq-Z2以外的开发板因为我们的编译目标是EdgeBoard FZ3A，所以boards目录下的Pynq-Z1、Pynq-Z2、ZCU104三个目录对我们来说就是多余的。然而PYNQ在编译过程中会遍历boards目录下的各个开发板并试图生成比特流文件。其中Pynq-Z2的输出会在pynq自身编译时用到，另外两个开发板的相关文件的编译纯属是浪费时间（关键是这步还特别费时），我怀疑这是个bug。因此，我们可以将Pynq-Z1、ZCU104两个文件夹删除。 Terminal12❯ cd &lt;pynq_repo_dir&gt;❯ rm -rf boards/Pynq-Z1 boards/ZCU104 完成之后，务必要提交到本地的Git版本历史中，否则不起作用（这是因为作者用git clone代替了cp）。 跳过boards/Pynq-Z2中各个Overlay生成比特流pynq作为一个Python的包，在编译过程中是要和其他packages一起安装到镜像中的。进行这一步时，它会将Pynq的本地repo先复制到sdbuild/build/PYNQ中，然后再运行其中的build.sh。观察这个脚本，我们可以看到PYNQ在编译Pynq-Z2/logictools和Pynq-Z2/base两个Overlay文件夹时，会先检查其中是否已存在同名的.bit、.hwh、.xsa文件，存在的话就跳过生成比特流的过程（即综合、布局布线等）。因此，我们可以先按照正常流程make BOARDDIR=... BOARDS=...，然后把生成的相关文件拷贝到原始的boards/Pynq-Z2目录中的对应文件夹下： Terminal123# 复制.xsa文件，.bit/.hwh文件类似处理❯ cp &lt;pynq_repo_dir&gt;/sdbuild/build/PYNQ/boards/Pynq-Z2/logictools/logictools.xsa &lt;pynq_repo_dir&gt;/boards/Pynq-Z2/logictools/❯ cp &lt;pynq_repo_dir&gt;/sdbuild/build/PYNQ/boards/Pynq-Z2/base/base.xsa &lt;pynq_repo_dir&gt;/boards/Pynq-Z2/base/ 注意这里的路径，是从sdbuild/build中的PYNQ复制到原始的PYNQ。和前面一样，要提交到Git版本历史中才会生效。 另外，经过实验证明，这里.xsa和.bit文件需要是同一次编译中产生，否则会发生一些奇怪且难以定位的错误。 后记搭建这个个人博客也有几年了，本想闲暇时写些技术文章，但没能持之以恒地保持输出。中间也曾断断续续写过一些论文阅读笔记，但都没有坚持下来。一方面是因为总担心自己粗浅的专业认识贻笑大方，另一方面是实验室的项目也确实不太合适作为写作素材，便一直没有动笔。EdgeBoard的事情我在去年COVID疫情期间动工后就一直搁置了，结果发现最近有不少人关心这个事情，就花了些时间算是给它画了个句号。我也以此为契机，提起了笔记录下整个过程。希望能够对大家有所帮助。","link":"/Engineering/pynq-compile/"}],"tags":[{"name":"Paper Lives Matter","slug":"Paper-Lives-Matter","link":"/tags/Paper-Lives-Matter/"},{"name":"AI Chip","slug":"AI-Chip","link":"/tags/AI-Chip/"},{"name":"Chisel","slug":"Chisel","link":"/tags/Chisel/"},{"name":"Chipmunk","slug":"Chipmunk","link":"/tags/Chipmunk/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"FPGA","slug":"FPGA","link":"/tags/FPGA/"},{"name":"PYNQ","slug":"PYNQ","link":"/tags/PYNQ/"}],"categories":[{"name":"Research","slug":"Research","link":"/categories/Research/"},{"name":"Engineering","slug":"Engineering","link":"/categories/Engineering/"}],"pages":[{"title":"About Me","text":"Welcome to my blog. I am Haozhe Zhu (朱浩哲). Currently I am a postdoctoral research fellow at the Frontier Institute of Chip &amp; System, Fudan University, with Qi Liu. I am also working closely with Chixiao Chen. Most of my works lie in a overlap of artificial intelligence and integrated circuits. Education 2017-2022, Ph.D in Microelectronics and Solid-state Electronics, Fudan University, with Xiaoyang Zeng. 2013-2017, B.Eng. in Microelectronics Science &amp; Engineering, Fudan University. Selected Publications Zhu, Haozhe, Bo Jiao, Jinshan Zhang et al. “COMB-MCM: Computing-on-Memory-Boundary NN Processor with Bipolar Bitwise Sparsity Optimization for Scalable Multi-Chiplet-Module Edge Machine Learning”, In 2022 International Solid-State Circuits Conference (ISSCC), pp. 250-252, IEEE, 2022. Link Zhu, Haozhe, Chixiao Chen, Shiwei Liu et al. “A Communication-Aware DNN Accelerator on ImageNet Using in-Memory Entry-Counting Based Algorithm-Circuit-Architecture Co-Design in 65nm CMOS.” In IEEE Journal on Emerging and Selected Topics in Circuits and Systems 10, no. 3 (2020): 283-294. Link Zhu, Haozhe, Yu Wang, and C.-J. Richard Shi. “Tanji: A General-Purpose Neural Network Accelerator with a Unified Crossbar Architecture.” IEEE Design &amp; Test 37, no. 1 (2019): 56-63. Link Jiao, Bo, Haozhe Zhu, Jinshan Zhang et al. “Computing Utilization Enhancement for Chiplet-based Homogeneous Processing-in-Memory Deep Learning Processors.” In 2021 31st Great Lakes Symposium on VLSI (GLSVLSI), pp. 241-246. ACM, 2021. (Co-first author) Link Visit the Google Scholar page to view the full publication list. About This BlogAll the posts on this site only represent my personal view. They are published under the CC BY-NC-ND 4.0 license.","link":"/about/index.html"},{"title":"FICS 服务器集群使用指南","text":"访问 GitHub 以获取最新文档：cihlab/fics-cluster-guide FICS 总体情况介绍FICS 服务器集群（FICS Is Computing Service, 下称 FICS）是芯片院的 EDA 与 AI 计算集群，包括若干计算队列： Hopfield - CPU 计算队列，用于 EDA 计算 Boltzmann - CPU 计算队列，用于 EDA 计算 Makkapakka - CPU/GPU 计算队列，用于 AI/GPU 计算 FICS 的主要架构如下图所示： 用户所有的操作都在登陆节点 mgmt01 上进行，计算任务需要用户手动提交到计算节点上进行。 请在使用 FICS 之前务必确认并理解： 妥善保管好您的账号、密码、VNC 密码！ 用户不允许在 FICS 上从事任何盈利性或其他与芯片院科研学习无关的工作； 用户不允许未经指导老师和管理员同意，将 FICS 上的任何文件分享到芯片院之外； 用户应当及时备份自己的文件和数据，FICS 尽可能保护您的数据安全，但无法做任何承诺； 提问之前请先阅读本文档和谷歌搜索，几乎所有问题都可以找到答案。 用户文档账号管理FICS 部署了专门的邮件系统，用于用户账号管理。您可以通过向系统发送邮件完成账号申请、密码重置等操作。绝大多数操作都是自动化的，您无需等待管理员的回复。 系统邮箱：techcrew@fics.top，请严格按照下列操作说明发送邮件。请不要通过这个邮箱联系管理员，如需邮件联系管理员请阅读文末的管理说明。 注意事项: 发送邮件前请确保邮箱可以正常收发邮件； 不要频繁发送邮件到系统中，系统处理邮件需要一定的时间，所以请耐心等待； 收到系统自动回复时间一般不超过 5 分钟（网络波动除外）； 若超过 5 分钟收不到系统回复邮件可以先查看垃圾邮箱。 账号申请请使用您的学号/工号邮箱进行下列操作（申请完成后您的账号会和您申请所用邮箱绑定）： 发送以 adduser xxxx 为标题的邮件到上述系统邮箱 (邮件标题前后没有空格，xxxx 为所需要申请到用户名，邮件内容任意)； 系统收到邮件后会在 3 分钟之内自动回复标题为“FICS: adduser wait for ack”的邮件，并等待管理员通过创建； 管理员会审核您的账号申请，无论通过与否，您都会收到一封说明邮件。 请注意： 如果您是芯片院的学生，请使用学号邮箱申请，且在发送邮件时必须抄送（cc）您的的日常指导老师，否则管理员不会受理； 由于 FICS 的用户日见增多，我们不再接受个性化的用户名（管理员需要对应到现实中的人），请参考以下几种例子选择用户名（例如我叫“朱浩哲”）：123名前姓后拼音全拼：haozhezhu 或 haozhe_zhu姓前名后拼音全拼：zhuhaozhe名前姓后且名使用拼音首字母：hzzhu（不推荐） 密码重置使用申请账号时所使用的邮箱： 发送以 resetpassword xxxx 为标题的邮件到上述系统邮箱（邮件标题前后没有空格，xxxx 为需要重置密码的用户名，邮件内容任意）； 系统收到邮件后会在 3 分钟之内处理请求并重置邮件对应账号的密码，并自动回复带有新密码的邮件（系统会检查重置的账号和邮箱的关联性，只有账号关联邮箱才会执行重置密码操作，无关联邮件会被无视）。 获取 FICS 文档使用申请账号时所使用的邮箱： 发送以 documentations 为标题的邮件到上述系统邮箱（邮件标题前后没有空格，邮件内容任意）。 系统收到邮件后会在 3 分钟之内处理请求并回复您。 鉴于您正在阅读本文档，您可以无视这一功能。 更改默认 Shell使用申请账号时所使用的邮箱： 使用申请账号时所使用的邮箱： 发送以 chsh xxxx 为标题的邮件到上述系统邮箱（邮件标题前后没有空格，xxxx 为需要设置的shell名字，如zsh、bash等，邮件内容任意）; 系统收到邮件后会在 3 分钟之内自动处理请求，请您重新登录您的账号。 bash 是您申请账号时的默认 Shell，zsh 比它功能更丰富（搭配 Oh-My-Zsh 等）但速度更慢。 基本使用如何登录 FICSFICS 的登陆节点是 mgmt01，您可以通过 SSH 登陆到该节点上，您可以使用任何支持 SSH 的终端工具： Terminal （Linux/macOS） PowerShell（Windows，自带） Putty（Windows，需另行安装，不推荐） 如果您目前处在校园网内，您可以直接使用 ssh 命令登陆： 123ssh username@10.155.102.33# 也可以使用下面这个（如果不想背出 IP 地址的话）ssh username@fics.local.zhutmost.com 其中 username 是您的用户名。 如果您成功登录，您会看到类似这样的界面： 请注意登录过程中需要您输入您的密码（在您申请账号成功的系统自动回复邮件中），第一次登录可能还会要求您确认证书（输入yes即可）。 如何用 VNC 连接远程桌面FICS 集群给每个用户分配了一个 VNC 端口，每个用户可以自行决定 VNC 服务的开关。在 SSH 登录后，您可以输入 vnc查看当前用户的 VNC 状态和端口： 请记住您的 VNC 端口，一般情况下它会是 5900 + userID，比如上图中的 5908。 用户通过 vnc 指令可以管理自己的 VNC 服务。 vnc start - 启动 VNC 服务。启动前请注意先设置 VNC 密码，否则 VNC 服务无法正常启动； vnc stop - 停用 VNC 服务； vnc restart - 重启 VNC 服务（遇到了奇怪的环境或显示问题，不妨先试试这个）； vncpasswd - 设置 VNC 密码（注意这个命令中间是没有空格的！）。 如果您已成功启动 VNC 服务，您可以使用 VNC 客户端访问您的远程桌面了。在这之前，由于上述 VNC 端口指的是登陆节点的端口，不是您本机的端口，因此您还需要先通过 SSH 进行端口转发，将这个端口映射到您本地的某个端口。您只需要在 SSH 登录时附带上 -L 本地端口:localhost:服务器VNC端口 参数即可，比如： 123ssh username@fics.local.zhutmost.com -L 60000:localhost:5908# 60000是您的本地的端口，10000-65535之间可以随便选（不要和自己电脑上其他服务冲突就行）# 5908是您的 VNC 端口，在上面的步骤中由服务器分配的 只要您的 SSH 连接不断开，您就可以利用 VNC 客户端连接 localhost:60000 来访问您的远程桌面了。VNC 客户端有很多，您可以自行选择： RealVNC VNC Viewer（Windows/Linux/macOS，需另行安装，官网下载）； Remmina（Ubuntu 等部分 Linux 发行版自带）； macOS 自带（Finder文件管理器窗口下按下 Cmd+K，然后输入 vnc://localhost:60000）。 请注意在 VNC 使用中，上述 SSH 连接不能断开（不要关闭 Terminal 或 PowerShell 窗口）。 VNC 桌面分辨率的设置和本地的 Linux 桌面设置方法一致，您可以在 VNC 桌面左上角的设置里找。 FICS 的文件存储尽管用户仅在登录节点 mgmt01 上操作，但对于计算节点来说，但是由于用户提交的任务需要计算节点读取相应的文件，因此以下目录都是所有节点可见的： 文件夹 位置 备注 用户 HOME 目录 /capsule/home/USERNAME EDA 目录 /capsule-ng/eda 分布式存储 PDK 目录 /capsule/pdk 其他软件目录 /capsule/opt 分布式通用存储目录 /lamport/shared 分布式存储 分布式 GPU 队列存储目录 /lamport/makkapakka 分布式存储，仅 GPU 队列 makkapakka 可见 其中， /capsule 目录（包括 HOME 目录和 PDK 等）是存储在 Capsule 储存节点服务器上的，文件 I/O 服务质量可能受该服务器的负载情况影响； /lamport 目录和 /lamport/shared 目录均是分布式存储，不受单个节点影响，有较高的 I/O 带宽（但对于大量小文件的情形会不太友好）； /lamport/makkapakka 和 /lamport/shared 类似，但它仅对 GPU 队列 makkapakka 可见； 我们为绝大多数共享目录都设置了内存缓存，以改善 I/O 性能。 因此，我们建议您尽可能将 EDA/AI 任务的大规模文件 I/O （例如 AI 数据集、仿真波形等）放在 /lamport/shared 或 /lamport/makkapakka 目录下，以获得更好的综合 I/O 性能。如果需要使用的话，您可以在对应的 /lamport/shared 或 /lamport/makkapakka 目录下创建一个和您的用户名完全一致的文件夹，把您的个人数据放在其中。 此外，任何情况下都不要在您的 HOME 目录下进行大规模文件 I/O（比如执行一些 Python 批处理脚本），会导致所有人都会变卡顿。 任务的提交与管理FICS 采用 SLURM 调度器进行计算任务到节点的分发。您可以阅读官方文档获取完整的 SLURM 使用方法。 这里仅列出一些常用的命令供参考： sinfo - 查看集群节点状态（应该能看到 hopfield/boltzmann/makkapakka 三组队列）； squeue - 查看当前队列中的任务；12squeue -u hzzhu # 查看 hzzhu 用户的任务squeue -p boltzmann # 查看 Boltzmann 队列上正在进行的任务 scancel - 取消已提交的任务；1scancel JOB_ID # 取消 JOB_ID 对应的任务，JOB_ID 可以通过 squeue 查看 srun - 提交交互式任务（不太熟悉 SLURM 的用户可以考虑使用 ilaunch/zlaunch 代替）； sbatch - 提交批处理任务； 考虑到不少 FICS 用户对于 Linux 的了解比较有限，我们对 srun 进行了简化的包装，帮助您更加简便地提交带图形界面的 EDA/AI 任务： ilaunch - 我们已经在 PATH 中添加了 ilaunch 命令，您可以直接使用它来提交任务。使用文档还在施工，暂时可以参考： ilaunch virtuoso - 将 EDA 软件分配到集群中去运行 ilaunch load ic/618 virtuoso - 可实现加载特别版本的 EDA 软件 ilaunch q makkapakka python - 参数 q 可以切换不同的计算队列，默认为 Hopfield ilaunch list - 可以打印当前已加载 EDA 列表 zlaunch - 与 ilaunch 类似，它是由 Haozhe Zhu 个人维护的。使用文档 EDA 软件环境设置我们设置了一套开箱即用的 EDA 环境，无需配置。默认加载的 EDA 软件及其版本如下： 点击展开显示 12345678910111213141516171819202122232425// ansysEM/21.1 powerartist/2021R2.2// comsolmultiphysics/5.5// xpeedicmetis/2023.01 snpexpert/2022.01// xilinxvivado/2020// mathworksmatlab/2020b// keysightads/2021u2// mentorcalibre/2020.3 modelsim/10.4c powerpro/10.3c tessent/2020.3// synopsystxs/2019.03 coretools/2017.06 nicc/2019.03 powerep/2020.03 hspice/2019.06 fusioncompiler/2019.12icv/2019.12 spyglass/2019.06 xa/2018.09 ppwr/2019.03 syn/2019.03 siliconsmart/2019.06verdi/2020.03 vc_static/2020.03 finesim/2020.03 prime/2019.03 sentaurus/2019.03 wv/2019.06icc2/2019.12 lc/2019.03 starrc/2019.03 vcs/2020.03 fm/2019.12// cadencegenus/20.1 jasper/2020.09 ssv/17.1 confrml/20.22 innovus/19.1 peakview/5.1skillpro/4.2F emx/5.6 liberate/18.1 xcelium/17.1 ic/618 qrc/16.1spectre/19.1// systoolshtop/2.2.0 python/3.9 如果您觉得已默认加载的软件的版本可以接受，可以忽略本节下面的内容。 FICS 采用 module 管理 EDA 软件环境。您可以阅读官方文档获取完整的 module 使用方法。 这里仅列出一些常用的命令供参考： module avail - 检查当前可用的 EDA 软件（&lt;L&gt; 后缀表示已加载，(default)后缀表示默认）； module load syn/2019.03 - 加载指定的 EDA 软件（这里以 syn/2019.03 为例）； module list - 列出已加载的全部 EDA 软件； module purge - 卸载所有已加载的 EDA 软件。 module unload syn/2019.03 - 卸载指定的 EDA 软件（这里以 syn/2019.03 为例），一般不需要使用该命令； 您可以通过 module avail 查看当前可用的 EDA 软件，通过 module load 加载相应的软件环境，比如： FICS 管理员无法处理 EDA 软件的使用问题，请您自行阅读 EDA 软件自带的文档； 如果您需要 Synopsys EDA 全家桶的文档，您可以前往 Haozhe Zhu 的 NAS 服务器获取。 ilaunch 在提交任务时，会使用默认的 EDA 环境（不会自动加载您已经 module load 的 EDA 软件），您可以参考 ilaunch 的文档。 GPU 炼丹相关TODO FICS 的管理绝大多数您的问题都可以通过阅读用户文档解决。如果您在使用 FICS 的过程中遇到了难以解决的问题，除了在办公室内询问其他人，您也可以通过以下方式与管理员或其他用户交流。 微信协调群如果您需要与其他用户或管理员交流讨论关于 FICS 使用的任何问题，都可以加入微信群。因为微信群的二维码会过期，所以这里就不附二维码了。 您可以询问其他人邀请您加入微信群。绝大多数电路设计方向的老师都已经在群里了，您可以考虑询问他们。 邮件联系管理员FICS 目前由 Kun Hu 维护，Haozhe Zhu 协助。联系方式如下： Kun Hu（胡坤）：i AT imux.top Haozhe Zhu（朱浩哲）：zhuhz AT fudan.edu.cn 请务必将上面所有管理员邮箱都列为收件人；如果您是芯片院的学生，请务必同时邮件抄送（cc）给您的日常指导老师。 由于管理员都是兼职的，可能无法及时回复，请谅解。","link":"/about/fics.html"}]}