{"posts":[{"title":"2023年智能芯片领域会议概览","text":"为了准确把握每一个学术交流（摸鱼）的机会，本文收集了智能芯片领域（固态电路、体系结构等）的相关学术会议的投稿信息，包括召开时间、地点、截稿时间等。之后，我将尽量保持本文持续更新。 由于多数会议的投稿截稿时间都会延期一至两周，因此下表中的截稿时间通常只是个大约时间。 固态电路 会议 地点 召开时间 截稿时间 网站链接 ISSCC’23 San Francisco, CA, US 2023.02.19 2022.09.07 Link VLSI’23 Kyoto, Japan 2023.06.11 2023.02.01 Link ESSCIRC’23 Lisbon, Portugal 2023.09.11 2023.04.14 Link ASSCC’23 Haikou, China 2023.11.05 2023.06.05 Link CICC’23 San Antonio, TX, US 2023.04.23 2022.11.14 Link HOTCHIPS’23 San Francisco, CA, US 2023.08.27 2023.03.22 Link 体系结构 会议 地点 召开时间 截稿时间 网站链接 ISCA’23 Orlando, FL, USA 2023.06.17 2022.11.14 Link MICRO’23 Toronto, Canada 2023.10.28 2023.04.21 Link HPCA’23 Montreal, Canada 2023.02.25 2022.08.01 Link DAC’23 San Francisco, CA, US 2023.07.09 2022.11.14 Link 机器视觉 会议 地点 召开时间 截稿时间 网站链接 CVPR’23 Vancouver, Canada 2023.06.18 2022.11.04 Link IROS’23 Detroit, MI, US 2023.10.01 2023.03.01 Link ICRA’23 London, UK 2023.05.29 2022.08.05 Link 其他会议 会议 地点 召开时间 截稿时间 网站链接 ISCAS’23 Monterey, CA, US 2023.05.21 2022.11.07 Link AICAS’23 Hangzhou, China 2023.06.11 2023.02.03 Link APCCAS’23 Hyderabad, India 2023.11.20 2023.06.04 Link MWSCAS’23 Phoenix, AZ, US 2023.04.07 2022.08.06 Link BioCAS’23 Toronta, Canada 2023.10.19 2023.06.09 Link GLSVLSI’23 Knoxville, TN, US 2023.06.05 2023.02.06 Link ICCAD’23 San Francisco, CA, US 2023.10.29 2023.05.15 Link ASP-DAC’23 Tokyo, Japan 2023.01.16 2022.07.24 Link DATE’23 Antwerp, Belgium 2023.04.17 2022.09.18 Link MLSys’23 Southern FL, US 2023.06.04 2022.10.28 Link FPGA’23 Monterey, CA, US 2023.02.12 2022.09.23 Link FPT’23 Yokohama, Japan 2023.12.11 2023.07.14 Link FPL’23 Gothenburg, Sweden 2023.09.04 2023.03.13 Link 祝大家投稿顺利～ photoed by Birmingham Museums","link":"/Research/asic-conf-ddl-2023/"},{"title":"2024年智能芯片领域会议概览","text":"为了准确把握每一个学术交流（摸鱼）的机会，本文收集了 2024 年智能芯片领域（固态电路、体系结构等）的相关学术会议的投稿信息，包括召开时间、地点、截稿时间等。 历史版本： 2023年智能芯片领域会议概览 由于多数会议的投稿截稿时间都会延期一至两周，因此下表中的截稿时间通常只是个大约时间。表中空白位置是还没有公布的信息，我会继续更新。 固态电路 会议 地点 召开时间 截稿时间 网站链接 ISSCC San Francisco, CA, US 2024.02.18 2023.09.06 Link VLSI Honolulu, HI, US 2024.06.12 2024.02.05 Link ESSERC* Bruges, Belgium 2024.09.09 2024.04.05 Link ASSCC Hiroshima, Japan 2024.11.18 CICC Denver, CO, US 2024.04.21 2023.11.06 Link HOTCHIPS Link * 欧洲固态电路会议（ESSCIRC）和欧洲固态器件研究会议（ESSDERC）从 2024 年起合并为欧洲固态电子研究会议（ESSERC）。 体系结构 会议 地点 召开时间 截稿时间 网站链接 ISCA Buenos Aires, Argentina 2024.06.29 2023.11.14 Link MICRO Link HPCA Edinburgh, Scotland 2024.03.02 2023.07.28 Link DAC San Francisco, CA, US 2024.06.23 2023.11.13 Link 机器视觉 会议 地点 召开时间 截稿时间 网站链接 CVPR Seattle, WA, US 2024.06.17 2023.11.03 Link IROS Abu Dhabi, UAE 2024.10.14 Link ICRA Yokohama, Japan 2024.05.13 2023.09.15 Link 其他会议 会议 地点 召开时间 截稿时间 网站链接 ISCAS Singapore 2024.05.19 2023.10.15 Link AICAS Dubai, UAE 2024.04.15 2023.10.15 Link APCCAS Taipei, Taiwan 2024.11.07 Link MWSCAS Western Springfield, MA, US 2024.08.11 2024.03.22 Link BIOCAS Xi’an, China 2024.10.24 Link GLSVLSI Link ICCAD Link ASP-DAC Incheon, South Korea 2024.01.22 2023.07.28 Link DATE Valencia, Spain 2024.03.25 2023.09.10 Link FPGA Monterey, CA, US 2024.03.03 2023.10.13 Link 推荐两个会议截稿时间的倒计时网站： AI Deadlines 收录了 AI 领域的诸多会议； CCF Conference Deadlines 收录了 CCF 建议会议。 祝大家投稿顺利～ photoed by Birmingham Museums","link":"/Research/asic-conf-ddl-2024/"},{"title":"🐿️ Chipmunk - 下降沿触发寄存器 RegNeg","text":"chipmunk 提供了在时钟负沿触发的寄存器 RegNegNext 和 RegNegEnable。它们具有和chisel3.RegNext、chisel3.util.RegEnable 类似的接口，唯一的区别是其在时钟的下降沿（而不是上升沿）完成数据锁存。 Why？Chisel 已经提供了一系列的时钟上升沿触发的寄存器，包括 RegInit、RegNext、RegEnable 等。有些场合下我们需要生成一些时钟下降沿采样的寄存器，但现阶段在 Chisel 中我们只能采用 BlackBox 的方法实现。 关于 Chisel 是否应该添加对时钟下降沿触发寄存器的原生支持，社区在 FIRRTL 时代就进行过一些讨论（如 #695）。尽管 Chisel 现在的后端 CIRCT Firtool 是支持生成 negedge clock 电路的，但目前 Chisel 前端还没有对应的结构。 Usagechipmunk 提供了四种不同签名的下降沿触发寄存器： Code Snippet1234RegNegNext(next: T)RegNegNext(next: T, init: T, isResetAsync: Boolean = true)RegNegEnable(next: T, enable: Bool)RegNegEnable(next: T, init: T, enable: Bool, isResetAsync: Boolean = true) 它们的参数功能如下： next：待锁存的输入数据，会在时钟的下降沿被采样。 init：复位初始数据；需要上下文中存在复位信号。 enable：锁存使能信号，当它为true.B时next会被锁存。 isResetAsync：复位信号是否为异步复位（AsyncReset）；默认为true。 用户不需要在参数列表中给定时钟和复位信号，和 Chisel 的 RegXXX 一样，它们会根据上下文使用对应的时钟和复位信号。 唯一需要注意的是参数isResetAsync。由于 Chisel 的类型系统限制，同步复位和异步复位的类型都是ResetType（除非显式声明为AsyncReset()，但这种情况不常见），Chisel 会在 Elaboration 阶段再推导决定它们属于哪种类型的复位信号并赋予对应的类型：Bool 或 AsyncReset。Chisel 没有提供公开 API 判断复位类型，因此需要用户通过设置 isResetAsync 告诉 RegNeg 最终使用哪种复位。 下面给出一些实际用例供参考。 Code Snippet12345678val nextVal0 = Wire(Vec(8, UInt(3.W)))val nextVal1 = Wire(SInt(3.W))val enable1 = Wire(Bool())withClockAndReset(clock, reset) { val r0 = RegNegNext(io.nextVal0, init = VecInit(Seq.fill(8)(1.U(3.W)))) val r1 = RegNegEnable(io.nextVal1, -3.S, io.enable1)} See Also Chipmunk Github photoed by Annegret Kammer","link":"/Engineering/chipmunk-regneg/"},{"title":"🐿️ Chipmunk - 用 Master&#x2F;Slave 定义 Bundle 方向","text":"chipmunk.IsMasterSlave 使用户在定义 Bundle 时可同时规定其属于数据的生产者（Master）或消费者（Slave）。当以 Master() 定义的 Bundle 被以 Slave() 形式例化时，内部信号的方向会自动翻转，反之亦然。 Why？chisel3.Bundle 在例化时，可以使用 Flipped() 翻转其内部信号的方向。在许多Chisel项目中，我们约定 Bundle 作为模块端口时默认是生产者，如果我们希望它作为消费者，则显式地用 Flipped() 把它包裹起来。然而，很多用户并不总是遵守这一约定，所以用户经常搞不清楚端口需不需要用 Flipped() 包裹起来。实践中，对于别人代码中的模块接口，通常需要阅读其代码和文档才能判断这些 Bundle 属于 Master 还是 Slave（是否需要翻转其方向）。 例如，如下代码片段中的 SRAM 读写接口 SramReadWriteIO 看起来非常合理，但根据上述约定，这一接口既然属于Slave，其内部信号方向应该反过来定义（比如 enable 应当是 Output()）。不遵守约定的结果，就是其他用户在调用这一 Bundle 的的时候经常会陷入困惑：我应不应该套上 Flipped()？ Code Snippet1234567class SramReadWriteIO extends Bundle { val enable = Input(Bool()) val read = Input(Bool()) val addr = Input(UInt(16.W)) val dataIn = Input(UInt(32.W)) val dataOut = Output(UInt(32.W))} Usagechipmunk.IsMasterSlave 是一个特质，用户在定义 Bundle 时可以选择混入这一特质。它要求额外定义一方法 def isMaster: Boolean，true 表示该 Bundle 当前的信号方向属于 Master，反之属于 Slave。 Code Snippet123456class SramWriteIO extends Bundle with IsMasterSlave { val enable = Input(Bool()) val addr = Input(UInt(16.W)) val dataIn = Input(UInt(32.W)) def isMaster = false // This is a Slave Bundle} 如此一来，在例化它时，用户可以用 Master() 或 Slave() 来选择它内部信号的方向。对于一个套上 Slave() 的 Master Bundle，其内部信号方向会相应取反。用户不需要关心何时需要 Flipped，只需要记住这一 Bundle 在当前模块的数据传输关系。 Code Snippet123456class Sram extends Module { val io = new Bundle { val rw = Slave(new SramReadWriteIO) } // ...} 此外，Master/Slave 还支持嵌套使用，从而允许用户构造出如下 AMBA AXI 总线这样的复杂例子。 Code Snippet123456789101112131415class AxiIO extends Bundle with IsMasterSlave { val aw = Master(new AxiWriteAddrChannelIO) val ar = Master(new AxiReadAddrChannelIO) val r = Slave(new AxiReadDataChannelIO) val w = Master(new AxiWriteDataChannelIO) val b = Slave(new AxiWriteRespChannelIO) def isMaster = true}class AxiSlave extends Module { val io = IO(new Bundle { val axi = Slave(new AxiIO) }) // ...} See Also Chipmunk Github photoed by Annegret Kammer","link":"/Engineering/chipmunk-master-slave/"},{"title":"🐿️ Chipmunk - Bits&#x2F;Data 等的更多方法","text":"chipmunk 为 Chisel 的原生类型 Bits/Data 等增加了若干额外的方法（主要是语法糖），为用户提供了一些更加便捷的编码选择，提高代码的可读性。 chisel3.Bits 的额外方法chisel3.Bits 是 Chisel 的 UInt/SInt/Bool 等类型的父类，因此以下方法可以被这些类型的实例调用。 这些方法是在 chipmunk.AddMethodsToBits 这个隐式类中实现的。 msb/lsb — 获取信号的最高/低 n 比特chisel3.Bits 已提供了类似的方法 x.head(n) 和 x.tail(n)，其中前者是获取该信号的高 n 比特，后者是去掉该信号的高 n 比特（相当于 x.head(x.getWidth - n)）。这两个方法显然是来自函数式编程语言处理队列的习惯（Haskell 用户狂喜），但和绝大多数硬件工程师的习惯很不一致，且导致代码可读性降低。硬件工程师习惯用“某某信号的高N比特/低N比特”来对多比特信号进行切片。 因此，Chipmunk 提供了 x.msb(n) 和 x.lsb(n) 两组方法，它们的功能正如方法名（most/least significant bits）：前者 x.msb(n) 和 x.head(n) 行为类似，后者 x.lsb(n) 则是获取该信号的低 n 比特。 具体如下： def msb(n: Int = 1): UInt返回当前信号实例的最高 n 比特。 def lsb(n: Int = 1): UInt返回当前信号实例的最低 n 比特。 def msb: Bool返回当前信号实例的最高 1 比特，注意返回类型为 Bool，与 msb() 不同。 def lsb: Bool返回当前信号实例的最高 1 比特，注意返回类型为 Bool，与 lsb() 不同。 setAll/clearAll/setAllTo — 将信号的所有比特赋 1 或 0将一个信号的所有比特赋 1 或 0 是一个很普遍的需求，SystemVerilog 中引入了专门的语法： Code Snippet12assign allOnes = '1;assign allZeros = '0; Chisel 中赋全 0 是容易实现的（x := 0.U），但赋全 1 缺乏优雅易读的实现方法。常见的写法包括： Code Snippet12x1 := Fill(x1.getWidth, b).asTypeOf(x1)x2 := ~ 0.U // ~ 0.S if SInt 无论如何，都很不直观。特别是如果我希望将所有比特赋值为某个 Bool 信号或某个 Scala Boolean 变量输出时，代码会变得更加难以阅读。 因此，Chipmunk 提供了 setAll/clearAll/setAllTo 等一系列方法。具体如下： def setAllTo(b: Bool): T将信号的每个比特都赋值为 b，并返回该信号。 def setAllTo(b: Boolean): T将信号的每个比特都赋值为 b 的 Bool 字面量（即b.B），并返回该信号。 def setAll(): T将信号的每个比特都赋值为 true.B，并返回该信号。 def clearAll(): T将信号的每个比特都赋值为 false.B，并返回该信号。 isOneHot — 判断当前信号是否为独热码（one-hot）如方法名的字面意思，判断当前信号是否为独热码。若是则输出 true.B，反之则输出 false.B。 chisel3.Data 的额外方法chisel3.Data 是 Chisel 的各硬件类型的父类。 这些方法是在 chipmunk.AddMethodsToData 这个隐式类中实现的。 dontTouch — dontTouch() 的语法糖chisel3.dontTouch 可以阻止 Chisel 对该信号进行优化，常用于保留某中间信号的命名、保留与模块输出无关的电路等。这是一个单例对象，下面是 Chisel 提供的一个用法等例子： Code Snippet123456789class MyModule extends Module { val io = IO(new Bundle { val a = Input(UInt(32.W)) val b = Output(UInt(32.W)) }) io.b := io.a val dead = RegNext(io.a +% 1.U) // normally dead would be pruned by DCE dontTouch(dead) // Marking it as such will preserve it} Chipmunk 提供了一个方法版本，可以直接调用 Data 类型的 dontTouch 方法实现同样的效果，为用户提供更多的编码选择。因此，上面的代码也可以写成下面这样，在有的时候这可以节省代码量。 Code Snippet12345678class MyModule extends Module { val io = IO(new Bundle { val a = Input(UInt(32.W)) val b = Output(UInt(32.W)) }) io.b := io.a val dead = RegNext(io.a +% 1.U).dontTouch} See Also Chipmunk Github photoed by Annegret Kammer","link":"/Engineering/chipmunk-bits-misc/"},{"title":"🐿️ Chipmunk Docs - DecoupledIO 增强版之 StreamIO","text":"在数字电路设计中，我们经常使用 Ready/Valid 握手协议来解耦数据流，Chisel 提供了 DecoupledIO 用以实现这一协议。然而，DecoupledIO 仅是一个预置的 Bundle，缺少与之配套的一系列常用组件（例如寄存器切片、Mux/Demux 等），此外它也未能搭配 chipmunk.IsMasterSlave。chipmunk 为 DecoupledIO 提供了一个“威力加强版”的 Ready/Valid 握手协议——chipmunk.StreamIO。 Ready/Valid 握手协议 Ready/Valid 握手协议由三部分信号组成： valid：表示数据有效，即上游数据已经准备好，可以被消费； ready：表示数据可被消费，即下游已经准备好接收数据； bits（即 payload）：表示数据本身。 其中，valid 和 bits 信号由上游产生，ready 信号由下游产生。当 valid 和 ready 信号同时有效时，bits 信号被传递，即数据被消费。利用这一协议，我们可以将数据流的生产和消费解耦：上游模块只需要在准备好数据后将 valid 和 bits 信号置为有效，而无需关心下游模块内部的状态；而下游模块只需要在准备好接收数据后将 ready 信号置为有效，当 valid 和 ready 信号同时有效时取走 bits 数据。通过使用 Ready/Valid 握手协议，开发者可以将注意力集中在自己负责的电路逻辑上，而无需过度关心其他模块的内部实现，从而提高开发效率。 需要注意的是，为了避免组合逻辑环路，我们要求 valid（及 bits）和 ready 信号不能同时依赖对方的当前状态。因此，在 Chipmunk（和其他绝大多数数字电路设计）中，我们约定 valid 不允许依赖于 ready 的当前状态，即上游模块不允许根据下游模块此刻是否 ready 来决定当前周期是否将 valid 置为有效。简单地说，用于 valid 产生的组合逻辑表达式中不能出现下游模块的 ready 信号。 关于 Ready/Valid 握手协议的更多细节，网上已经有了丰富的材料可以参考，这里不再赘述。 关于 StreamIOWhy?Chisel 提供了 DecoupledIO 和 IrrevocableIO 两个 Ready/Valid 握手协议的 Bundle 实现，它们都继承自 chisel3.ReadyValidIO。Chisel 并未为这两个接口提供太多 API，基本上只有： def fire: Bool = ready &amp;&amp; valid，表示当前周期是否发生了数据传输； class Queue，以 ReadyValidIO 为接口的同步 FIFO； def map[T](f: T =&gt; T2): T，用于对 bits 进行变换。 IrrevocableIO 其实在实现上 DecoupledIO 并无区别，只是约定它的 bits 在 valid 有效但 ready 无效时不会改变，即数据不可撤回。两者的实际差别有赖于具体模块中的电路实现。 很显然，上述 API 不足以应付实际的设计需求。 Chipmunk 在 chisel3.ReadyValidIO 的基础上提供了 chipmunk.StreamIO，它继承自 chisel3.ReadyValidIO，并提供了一系列常用的 API 和特性，包括： 一系列类似fire 的语法糖，展现数据传输的不同状态； 符号化的连接方法，类似 a &gt;&gt; b &gt;-&gt; c，可以很容易地看出数据的流向； 针对 bits 的一系列操作，包括 Map、Cast 等； 一系列常用的组件，包括寄存器切片（Register Slice）、Fork/Join、Mux/Demux 等。 StreamIO 在实现上参考了 SpinalHDL 的 Stream 的 API 设计，熟悉 SpinalHDL 的同学应该会有一丝熟悉的感觉。 UsageStreamIO 例化 创建一个 StreamIO，其 payload 类型为 UInt： Code Snippet1val myStream = Wire(Stream(UInt(32.W))) 创建一个 StreamIO，其 payload 类型和另一个 DecoupledIO 的 bits 一致： Code Snippet12val myDecoupled = Wire(Decoupled(UInt(32.W)))val myStream = Wire(Stream(myDecoupled)) 请注意这里 myStream 不会与 myDecoupled 有任何电路连接（比如共享 bits），而是会创建一个新的 UInt 作为 payload。 创建一个空的 StreamIO（即其 payload 类型为 EmptyBundle）： Code Snippet1val myStream = Wire(Stream.empty) 空的 StreamIO 一般用于声明时没有确定 payload 类型的情况，后续可以搭配 payloadReplace 等 API 赋予具体的 payload。 流控与状态指示StreamIO 提供以下状态指示方法，它们的返回类型均为 Bool： 语法 描述 x.fire 当前周期正在进行数据传输，即 ready &amp;&amp; valid x.isPending 上游数据已经就绪，但下游未能准备好接收，即 !ready &amp;&amp; valid x.isStarving 下游已准备好接收数据，但上游没有发起传输，即 ready &amp;&amp; !valid StreamIO 也提供下列方法对数据流进行流控，它们会返回一个新的 StreamIO： 语法 描述 x.haltWhen(cond) 当 cond 为 True 时，数据传输会被阻断，即上下游模块均无法完成握手。 x.continueWhen(cond) 相当于 x.haltWhen(!cond) x.throwWhen(cond) 当 cond 为 True 时，数据传输会被丢弃，即上游模块发起的数据传输都会成功握手，但下游模块不会收到相应的数据。 x.takeWhen(cond) 相当于 x.throwWhen(!cond) Payload 变换 StreamIO 允许对 payload 直接进行一系列变换，包括： Code Snippet123def payloadMap[T2 &lt;: Data](f: T =&gt; T2): StreamIO[T2]def payloadReplace[T2 &lt;: Data](p: T2): StreamIO[T2]def payloadCast[T2 &lt;: Data](gen: T2, checkWidth: Boolean = false): StreamIO[T2] 上述方法会返回一个新的 StreamIO，其 payload 会变成变换后、类型为 T2 的新信号，同时其 ready 和 valid 信号会连接到当前 StreamIO 的 ready 和 valid 信号。 payloadMap 可以将函数 f 作用于 payload，比如： Code Snippet12val streamOld = Wire(Stream(UInt(32.W)))val StreamNew = streamOld.payloadMap(_ + 1.U) payloadReplace 会将 payload 替换为 p，相当于 payloadMap(_ =&gt; p)，比如： Code Snippet123val streamOld = Wire(Stream(UInt(32.W)))val anotherBool = Wire(Bool())val StreamNew = streamOld.payloadReplace(anotherBool) payloadCast 会对 payload 进行强制类型转换，相当于 payloadMap(_.asTypeOf(gen))，比如： Code Snippet12val streamOld = Wire(Stream(UInt(32.W)))val StreamNew = streamOld.payloadCast(SInt(32.W), checkWidth = true) 其中参数 checkWidth = true 允许检查类型转换前后的位宽是否一致，如果不一致抛出异常。该参数默认为 false，即不会检查位宽，如果位宽不一致会自动截断或扩展。 寄存器切片（Register Slice）为 StreamIO 插入寄存器切片以改善时序，是一个常见的需求。然而，这实现起来非常繁琐且易错。显然，我们不能直接在 StreamIO 的 ready/valid/bits 路径上贸然插入寄存器切片。valid 和 ready 分别代表当前周期上游模块和下游模块的状态，在它们的传播通路上引入寄存器会导致状态延后若干周期才会传播到对侧。这会导致上下游模块无法在正确的时机完成握手，可能会引起数据丢失或吞吐下降。 根据寄存器插入位置不同，StreamIO 提供： pipeForward：前向寄存器切片，切断从上游模块到下游模块的 valid 和 bits 通路的组合逻辑路径；Code Snippet1val streamNew = streamOld.pipeForward() 它在性能上不会引入吞吐下降（虽然会增加 1 周期延时），在面积上代价是 N + 1 个寄存器（N 是 bits 位宽）以及少量组合逻辑。 pipeBackward：后向寄存器切片，切断从下游模块到上游模块的 ready 通路的组合逻辑路径。Code Snippet1val streamNew = streamOld.pipeBackward() 它在性能上不会引入额外的延时和吞吐下降，在面积上代价是 N + 1 个寄存器（N 是 bits 位宽）、N 个 2:1 MUX 以及少量组合逻辑。 pipeAll：双向寄存器切片，同时切断 valid、bits、ready 通路的组合逻辑路径。Code Snippet1val streamNew = streamOld.pipeAll() 相当于 streamOld.pipeForward().pipeBackward()，因此它会引入 2N + 2 个寄存器（N 是 bits 位宽）、N 个 2:1 MUX 以及少量组合逻辑。 pipeSimple：双向寄存器切片，同时切断 valid、bits、ready 通路的组合逻辑路径。Code Snippet1val streamNew = streamOld.pipeSimple() 它至多每隔一个周期握手一次，因此会引起最高可达一半的吞吐损失，但面积上只需要 N + 2 个寄存器以及少量的组合逻辑。与 pipeAll 相比，它的面积代价更小，但会引入额外的性能损失。 pipeValid：仅切断 valid 通路的组合逻辑路径。Code Snippet1val streamNew = streamOld.pipeValid() 面积上仅需要 1 个寄存器和少量组合逻辑。 pipPassThrough：什么都不做，返回当前的 StreamIO。Code Snippet1val streamNew = streamOld.pipPassThrough() 符号化连接StreamIO 提供了一系列方法用于连接其他 StreamIO： 语法 描述 x.connectFrom(y) 用 y 驱动 x，即 y 作为 x 的上游进行连接 ready、valid、bits 信号 x.handshakeFrom(y) 和 connectFrom 类似，但只连接 ready、valid 信号，不连接 bits 信号 x &lt;&lt; y 相当于 x.connectFrom(y)，返回 y x &gt;&gt; y 相当于 y.connectFrom(x)，返回 y x &lt;-&lt; y 相当于 x &lt;&lt; y.pipeForward()，返回 y x &gt;-&gt; y 相当于 x.pipeForward() &gt;&gt; y，返回 y x &lt;|&lt; y 相当于 x &lt;&lt; y.pipeBackward()，返回 y x &gt;|&gt; y 相当于 x.pipeBackward() &gt;&gt; y，返回 y x &lt;+&lt; y 相当于 x &lt;&lt; y.pipeAll()，返回 y x &gt;+&gt; y 相当于 x.pipeAll() &gt;&gt; y，返回 y 借助 &lt;&lt;、&gt;&gt; 等流操作符，我们可以实现可读性较强的 StreamIO 连接甚至级连，比如： Code Snippet123val s1 = Stream(UInt(8.W))s1 &lt;-&lt; uAnotherModule.io.outStreams1.haltWhen(somethingEnable) &gt;&gt; uSomeModule.io.inStream 配套组件Chipmunk 包括了一系列 StreamIO 的配套组件。 StreamFork/StreamJoinStreamFork 可以将一个上游 StreamIO 分叉成多个下游 StreamIO，每个下游 StreamIO 会分别完成仅一次握手，上游 StreamIO 会在所有下游 StreamIO 完成握手后才完成握手。为了提高性能，每个下游 StreamIO 是否握手是独立进行的，当它 ready 有效时即完成握手，而不需要等到所有下游 StreamIO 的 ready 都有效。 StreamJoin 可以将多个上游 StreamIO 合并成一个下游 StreamIO，当且仅当所有上游 StreamIO 的 valid 都有效时，才会发生握手。 在 object StreamFork/object StreamJoin 中，Chipmunk 提供了多个接口略有差别的方法。用户可以阅读代码中的注释，根据自己的需求选择合适的方法。 StreamMux/Demux/…TODO See Also Chipmunk Github photoed by Annegret Kammer","link":"/Engineering/chipmunk-stream/"},{"title":"SSH 通过 443 端口连接 GitHub","text":"GitHub 提供了两种协议供用户使用 Git 连接—— SSH 和 HTTPS。理论上我可以随意选择两者之一连接到我在 GitHub 上的代码仓库，无论是将云端的仓库 clone 到本地，还是将本地的修改 push 到云端。然而，出于一些奇奇怪怪的原因，我所在的办公网络环境禁止了 22 端口，而 22 端口正是 GitHub 提供 SSH 访问的端口号。尽管可以换用 HTTPS 协议，但无论如何将我电脑上的所有代码仓库的上游都从 git@github.com:... 修改称 https://github.com/... 仍然是一个繁重的体力活。 为了一劳永逸地解决这个问题，最理想的解决方式是让 Git 的 SSH 协议改用 22 以外的其他端口连接 GitHub。 SSH 连接失败我们在 clone GitHub 上的代码仓库时，可以看到 GitHub 提供了两种不同的链接（以我的 SpinalHDL 模版仓库为例）： Terminal12git clone https://github.com/zhutmost/spinalhdl-template.git # HTTPSgit clone git@github.com:zhutmost/spinalhdl-template.git # SSH 其中第一种方式，即 HTTPS 协议，一般总能可以工作（只要能在浏览器里打开 GitHub），而后者依赖 SSH 的正常工作。因为我的网络环境阻断了 22 端口的连接，所以我测试 GitHub 的 SSH 连接时会出现以下报错： Terminal123❯ ssh -T git@github.comkex_exchange_identification: Connection closed by remote hostConnection closed by xx.xx.xx.xx port 22 而在理想情况下，上述命令应当输出： Terminal12❯ ssh -T git@github.comHi zhutmost! You've successfully authenticated, but GitHub does not provide shell access. 奇妙的冒名顶替仔细发掘 GitHub 的文档，可以发现 GitHub 在另一个域名（ssh.github.com）上提供了一个 443 端口的 SSH 服务。显然，防火墙一般不会阻拦 443 端口（只要能浏览 GitHub 网站就能连上），可以用下面的命令进行测试： Terminal1❯ ssh -T -p 443 git@ssh.github.com 为了让Git也能通过上述端口用 SSH 访问 GitHub，我们为上述 SSH 连接方式设置一个别名。首先找到SSH的配置文件，它的路径一般是 ~/.ssh/config，如果这个文件不存在的话也可以创建一个。然后，在其中增加以下内容： ssh_config1234Host github.com HostName ssh.github.com User git Port 443 其中，Host 是别名，HostName 是实际的域名地址，Port 是端口号。因为我希望当我在用 SSH 连接 github.com 时，实际访问的是 ssh.github.com，所以 Host 和 HostName 分别设置成这两个域名（注意不要颠倒顺序）。 如此一来，ssh.github.com 就成为了 github.com 的“冒名顶替”者。当 Git 通过 SSH 协议试图访问 github.com 的时候，SSH 会发现它是 ssh.github.com 的别名，因此会用 443 端口实际连接到后者。这样，就绕开了本地网路环境对 22 端口的限制。 （我之所以使用上述方法，是因为我的网络情况比较复杂。建议公司的朋友在使用暗渡陈仓之策前，先和 IT 部门确认下是否合规。） Thumbnail by Besthqwallpapers","link":"/Engineering/github-ssh-443/"},{"title":"EdgeBoard 的 PYNQ 移植","text":"PYNQ 是我很喜欢的一个 FPGA 开源工具。它将 Zynq 上的各种硬件资源用 Python 封装了起来，允许用户通过 Jupytor Notebook 远程调试 FPGA。将 PYNQ 移植到 Baidu EdgeBoard 上是我去年在 COVID 疫情期间开的坑（具体请参看我的 GitHub），但中间遇到的小问题有点多，便一直没有完全填上。我最近抽出了些时间重新拾起了这个事情，就顺便把整个过程和遇到的问题都记录下来，以飨后来者。 相关源代码已开源至 Github，预编译 PYNQ 镜像文件我也已上传至阿里云盘。因为设备有限，我没有为这个镜像进行所有外设的上板测试。如果你发现了任何问题，欢迎和我联系。 PYNQ官方提供了 SD 卡镜像编译的文档，因此一些比较明确的步骤我可能不会详述，请搭配官方文档阅读。 为了避免混淆，这里先澄清一下很多朋友的一个小误解：本文中的PYNQ指的是 PYNQ 框架（本质上是一个 Ubuntu），而非那两个粉色的开发板（PYNQ-Z1 和 PYNQ-Z2）。PYNQ 可以部署在 PYNQ-Z1 和 PYNQ-Z2 上，也可以部署在其他 Zynq 系列的 FPGA 上。 开始之前Xilinx 提供了 PYNQ-Z1、PYNQ-Z2、ZCU104 等开发板的镜像，可以直接从PYNQ网站上下载到，具体列表可以在 PYNQ 的下载页面找到（也包括 Ultra96 等第三方开发板）。如果我们想要在此外的开发板（比如本文中的 EdgeBoard Lite）上使用 PYNQ，就需要自己编译PYNQ镜像。 本文的编译目标是 PYNQ v2.7。本文写作时（2021 年 8 月）PYNQ2.7 的开发已经完成，但是还没有合入主线分支，文档也没有更新（但差别不大，反正各种奇奇怪怪的 bug 本来也不会写在文档里）。每次大版本（即 2.X）更新后，随着时间推移，依赖软件包之间会出现五花八门的兼容性问题，这些问题很可能要到下一次 PYNQ 大版本更新才会一次性修复。这个问题主要得归咎于 Xilinx 官方，PYNQ 的编译中依赖的很多软件都不指定特定版本。因此，如果你看到本文时已是很久之后，文章中遇到的问题和你遇到的可能不尽相同。 硬件上，除了 Edgeboard 本身，我准备了一台半淘汰的笔记本搭建编译环境。这个不是很重要（虚拟机也不是不可以），唯一需要确认的是剩余磁盘空间要够大（大约 200GB）。 PYNQ v2.7 需要 Vivado/Vitis/PetaLinux 的版本为 2020.2。我的操作系统是 Ubuntu 18.04.5 LTS。Vivado/Vitis 2020.2 最高支持 Ubuntu 18.04.4，安装时需要修改 /etc/os-release 骗过安装程序。这里操作系统的版本建议请严格按照 Xilinx 的安装指南，我不建议你和我一样操作。 编译过程中需要从互联网上下载大量依赖组件，请确保你能够自由访问互联网。 理想的编译过程设置 PYNQ 环境首先将 PYNQ 的 GitHub Repo 复制到本地，并切换到 image_v2.7 分支。 Terminal123❯ git clone https://github.com/Xilinx/PYNQ.git pynq❯ cd pynq❯ git checkout image_v2.7 我们接下来的主要工作都在 sdbuild 目录下进行。先运行 scripts/setup_host.sh，它会用 apt 安装各种需要的包，以及下载 QEMU 和 CrossTool-NG。 Terminal1❯ source ./scripts/setup_host.sh 这个脚本运行需要很久的时间（主要是因为下载 QEMU 和 CrossTool-NG 的安装包），但好在只需要运行一次。 后续编译过程还会依赖 Ninja，然而该脚本中没有安装，因此我们手动安装下。 Terminal1sudo apt install ninja-build 到这里，Xilinx 全家桶需要的各种依赖包也安装完成了，接下来就可以安装Xilinx全家桶了。 安装 Xilinx 全家桶我们需要安装 Vivado、Vitis、PetaLinux 三个软件。按照 PYNQ v2.7 的版本要求，三者的版本都必须是 2020.2。这里需要注意的是，不要使用管理员权限安装。 Vivado 和 Vitis 是通过同一个安装程序安装的，安装时命令行运行 ./xsetup，勾选需要的组件即可。 PetaLinux 安装的命令如下： Terminal1❯ petalinux-v2020.2-final-installer.run --dir &lt;xilinx_install_dir&gt;/petalinux/2020.2 --platform &quot;aarch64 arm&quot; 具体安装选项可以参考 UG1144。这里存在一个坑，PetaLinux 的安装程序允许用户任意指定安装位置，但是 PYNQ 之前的版本默认却要求它的路径必须是.../2020.2/的形式（v2.7 有无修复不确定，我没有去测试）。 安装完成后，我们需要将下面几行代码加入 .bashrc（也可以每次打开命令行手动执行）。这样一来，就可以在命令行中运行这些软件了。 .bashrc123source &lt;xilinx_install_dir&gt;/petalinux/2020.2/settings.shsource &lt;xilinx_install_dir&gt;/Vivado/2020.2/settings64.shsource &lt;xilinx_install_dir&gt;/Vitis/2020.2/settings64.sh 添加自定义开发板PYNQ在 boards 文件夹下预置了 Pynq-Z1、Pynq-Z2、ZCU104 三个与对应开发板同名的文件夹。它们的内部结构大同小异，主要分成以下五个部分： notebooks； petalinux_bsp； packages； base、logictools 等 Overlay 文件夹； &lt;board_name&gt;.spec。 下面简单介绍下这些文件和文件夹的功能，具体的细节（如果你需要定制一些复杂的东西）还请自行阅读PYNQ的编译脚本源代码。 notebooks 文件夹会原样复制到最终的用户目录下，每次大家打开 Jupyter Notebook 后看到的就是它。这个文件夹里的内容不是很重要，一般都是放些教程。 petalinux_bsp 文件夹用于 PetaLinux 生成 BSP，它只在 sdbuild/scripts/create_bsp.sh 脚本中用到。该文件夹里边包括两个文件夹 meta-user、hardware_project。其中，meta-user 文件夹会被复制到PetaLinux项目文件夹下的 project-spec/meta-user，里面放设备树文件、各种用户配置等（如果你对 PetaLinux 项目的目录结构不了解的话可以参考 UG1144）。hardware_project 里需要放 .xsa 硬件描述文件（该文件由 Vivado 导出），或者也可以放一些脚本（至少包括一个 Makefile）供 PetaLinux 实时地生成 .xsa 文件。如果用户在 &lt;board_name&gt;.spec 中指定了 BSP，那么 hardware_project 不会被用到。这里一个文档中一个没有注明的是，meta-user 总是会起作用，即使你指定了 BSP，它也会覆盖掉里边的 meta-user 并重新打包。 packages 文件夹的结构和 sdbuild/packages 的结构类似，这两个目录下的每个文件夹对应一个个的组件，在编译过程中会被安装到 RootFS 中。安装过程主要是在 sdbuild/scripts/install_packages.sh 中进行。如果你需要增加组件，建议阅读此脚本和 sdbuild/packages/README.md 了解更多细节。 其他文件夹中如果存在 Makefile 文件，就会被认为是 Overlay 文件夹。在编译 pynq 本身时，&lt;pynq_repo_dir&gt;/build.sh 脚本会试图进入这些文件夹，并挨个检查是否存在 .bit、.hwh、.xsa 等文件。这些文件夹不是必须的，主要是为用户提供一些针对该开发板的预置 Overlay。 &lt;board_name&gt;.spec 文件描述了针对该开发板的各种配置和文件路径。它的格式如下所示： board_name.spec123456ARCH_&lt;board_name&gt; := aarch64 # Zynq的CPU架构，可以是aarch64或armBSP_&lt;board_name&gt; := ... # 开发板的BSP文件（如果有的话）BITSTREAM_&lt;board_name&gt; := ... # 默认的比特流文件FPGA_MANAGER_&lt;board_name&gt; := 1STAGE4_PACKAGES_&lt;board_name&gt; := pynq ethernet ... 注意这里的 board_name 要和文件夹的名字一致。 接下来我们可以依样画葫芦为自己的开发板配置这些文件了。我在 edgeboard 的仓库中放置了针对 EdgeBoard Lite 的配置文件，如果需要的话你也可以参考。 一把梭编译，赌人品按照官方的流程，理论上我们可以开始进行漫长的编译了。不过我强烈建议你先阅读下后续的几个章节再开始编译（可以避免很多无谓的时间浪费）。 在 sdbuild 下运行： Terminal1❯ make BOARDDIR=&lt;edgeboard_repo_dir&gt;/edgeboard/pynq BOARDS=edgeboard-fz3a 运气不错的话，我们能够在几个小时后获得最终的 SD 卡镜像 edgeboard-fz3a-2.7.0.img，然后就可以将其烧写到 SD 卡上了。 Terminal1❯ sudo dd if=&lt;pynq_repo_dir&gt;/sdbuild/output/edgeboard-fz3a-2.7.0.img bs=1M of=/dev/mmcblk0 &amp;&amp; sync 注意这里你的SD卡设备名可能不是 /dev/mmcblk0，请务必再三确认，以免写入其他磁盘丢失数据。 各种常见和不常见的 Bug实践中，上一步十之八九会遇到各种奇奇怪怪的问题，然后报错退出。这里我没法给出一个万能方法，只能说“具体情况，具体分析”。记得多翻日志，多问谷歌。 我把各种我遇到的问题罗列于此，并提供了我的原因分析和解决方法。 NodeJS 安装时报错 base_files is not configured在运行到 sdbuild/packages/jupyter/qemu.sh 时，它会用 apt 安装 NodeJS（这是运行 Jupyter Notebook 必要的）。此时，apt 安装无法完成，并出现以下报错： Terminal123456789101112131415Setting up base-files (11ubuntu5) .../bin/rmdir: failed to remove '/var/run': Directory not emptydpkg: error processing package base-files (--configure): installed base-files package post-installation script subprocess returned error exit status 1dpkg: dependency problems prevent configuration of bash: bash depends on base-files (&gt;= 2.1.12); however: Package base-files is not configured yet.dpkg: error processing package bash (--configure): dependency problems - leaving unconfiguredErrors were encountered while processing: base-files bashNo apport report written because the error message indicates its a followup error from a previous failure.E: Sub-process /usr/bin/dpkg returned an error code (1) 它提示 NodeJS 在安装时需要访问一个名为 base-files 的组件，但是该组件在此时还没有完成 “configure”。我们沿着这个信息往上追溯的话，会一直找到 RootFS 的初始化，此时该组件应当完成安装。 PYNQ 采用 Multistrap 作为 RootFS 的初始化工具，它利用 apt 下载所需要的包并进行安装。base-files 正是其中一个此时应当被安装的包，完整的包列表可以见 ubuntu/focal/aarch64/multistrap.config。观察安装日志，可以最终定位到真正的错误原因：base-files的安装会用到 chmod，这要求另一个名为 base-passwd 的包必须比它先完成 “configure”，否则 base-files 的安装就会失败。简而言之，就是 base-files 依赖 base-passwd。 那么问题来了，为什么 RootFS 初始化时部分包安装失败后不会报错呢？原因在 sdbuild/scripts/create_rootfs.sh 脚本中如下的两行代码抑制了 postinst1.sh 和 postinst2.sh 两个脚本的报错： create_rootfs.sh123$dry_run sudo -E chroot $target bash postinst1.sh... # other stuff$dry_run sudo -E chroot $target bash postinst2.sh 因此此处即使发生安装失败，程序也会继续执行下去。 更为本质的一个问题是为什么 dpkg 无法检测到上述两个软件包之间的依赖关系。这已经超出了 PYNQ 的范畴，根据 Debian 社区的意思大体上可以这么理解：base-files 和 base-passwd 都是属于Essential的包，理论上它们都是必装的，因此就没有设置依赖关系。如果我们为这些必装的组件之间相互设置依赖关系的话，会陷入循环依赖的地狱。那么在安装时它们之间发生依赖冲突怎么办呢？这个问题至少在 2011 年就有人提出过，社区的结论是这个问题并不常见（多数时候 base-passwd 总比 base-files 先完成 “configure”），所以不妨依靠玄学。他们认为这个问题在新的 Multistrap 版本上不会出现，然而并不。 这里我的解决方法是手工指定 dpkg --configure 的顺序，将 sdbuild/scripts/create_rootfs.sh 的 postinst1.sh 部分中原先的 dpkg --configure -a 修改成： create_rootfs.sh1234# 先完成base-passwd的configuredpkg --configure gcc-10-base libcrypt1 libc6 libgcc-s1 libdebconfclient0 base-passwd# 再完成其他组件的configuredpkg --configure -a python2.7-minimal安装失败与上个问题类似，有时会出现 python2.7-minimal 这个包的 configure 失败。这个问题本身不是很严重，因为 postinst1.sh 和 postinst2.sh 两个脚本会各执行一遍 dpkg --configure -a，因此第一遍中极少量没成功安装的包会在第二遍中完成安装（比如 cups-pk-helper 这个包经常如此）。然而，因为有大量包依赖于 python2.7-minimal，一旦它安装失败后，一连串的包会一同安装失败，然后安装程序就崩了。 这里可以从报错信息中观察到，安装失败的原因是它的 postinst 脚本中用到了 awk，然而此时 awk 这个命令还未安装。解决方法也和上个问题类似，即手工指定 dpkg --configure 的顺序，确保提供 awk 命令的包比 python2.7-minimal 先完成 configure。有很多包都提供了 awk 命令，我这里选择了 mawk。 create_rootfs.sh12dpkg --configure &lt;... 其他需要提前`configure`的包&gt; mawkdpkg --configure -a 无法从SD卡启动，找不到RootFS这个问题深究起来非常复杂，现象是烧写完 SD 卡上板卡后，无法完成开机，屏幕/串口会显示内核错误。其中括号里的数字我这边是 179,2 和 179,10 两种情形之一（我没有彻底弄清楚这俩数字的含义）。 1Kernel Panic - not syncing: VFS: Unable to mount root fs on unknown-block(179,10) 关于 SD 卡的一系列 bug 都会引起这个报错。首先请确保 SD 卡烧写成功，烧写完成后可以在 Ubuntu 中挂载并尝试打开检查一下，如果不能正常打开的话重新烧写下。然后请参考以下几点依次排查。因为该报错的原因很多，我这里可能列举不全，见谅。 使用 dd 烧写时块尺寸不合适RootFS 分区的文件系统是 Ext4，它在开机时会检查分区尺寸，因此如果在 dd 时使用过大的块尺寸（block size，也就是 bs=... 参数），就会无法通过分区尺寸的检查。 比如用 4M 的块尺寸烧写镜像的话（即 sudo dd bs=4M if=... of=...），开机就会保错。在我这使用 1M 的块尺寸是正常的，具体命令可以看前文。 SD卡的写保护这个问题似乎是来自于很多人使用了淘宝购买 EdgeBoard FZ3A 开发板时店家提供的所谓 “Vivado 参考设计”。这个参考设计中关于 SD 卡的配置存在错误，它打开了 SD 卡槽的写保护引脚。但是据 WhyCan Forum 社区的文章指出，EdgeBoard 的 PCB 设计中去掉了这一引脚。因此，我们稳妥起见，可以在设备树中禁用掉写保护功能。 如前文所述，PYNQ 为我们提供了一个修改设备树的接口，就是 boards/&lt;board_name&gt;/petalinux_bsp 文件夹。我们先在相应目录下创建一个设备树文件： Terminal123❯ mkdir -p &lt;pynq_repo_dir&gt;/boards/&lt;board_name&gt;/petalinux_bsp/meta-user/recipes-bsp/device-tree/files❯ cd &lt;pynq_repo_dir&gt;/boards/&lt;board_name&gt;/petalinux_bsp/meta-user/recipes-bsp/device-tree/files❯ touch system-user.dtsi 然后对 sdhci1 节点（对应于 PS_SD1，即我们的 SD 卡槽）进行修改。完成以后，你的 system-user.dtsi 文件应该长这个样子： system-user.dtsi12345678910/include/ &quot;system-conf.dtsi&quot;/ { /*根节点，这里保持不变*/};&amp;sdhci1 { status = &quot;okay&quot;; max-frequency = &lt;50000000&gt;; no-1-8-v; /*我其实不太理解这行的作用，但反正一出兼容性问题，大家就会写这个*/ disable-wp; /*关掉写保护功能*/} 理论上如果使用我自己做的 Board Files 里的 Zynq Preset，是不会遇到这个问题的（不过我没试，重新编译太费时了）。 Boot 参数中设置了错误的 root 分区位置PYNQ 默认总是从 /dev/mmcblk0（这个路径是 PYNQ 上的，不是你的宿主 Ubuntu 上的）启动系统，即它如果它有多个 SD 外设的话，SD 卡要连在 PS_SD0上。不幸的是，EdgeBoard 还真的有两个 SD 设备，一个是我们的 TF 卡槽，另一个是一颗 eMMC Flash 芯片。默认情形下，PYNQ 总是会尝试从后者启动，而我们的系统实际存放在SD卡上。 PetaLinux 的 Boot 参数是通过设备树中的 /chosen/bootargs 条目进行配置的。默认情况下，最后镜像使用的设备树中该条目会是这样的（每个字段的先后顺序不重要）： system-user.dtsi1bootargs = &quot;root=/dev/mmcblk0p2 rw earlyprintk rootfstype=ext4 rootwait devtmpfs.mount=1 uio_pdrv_genirq.of_id=\\&quot;generic-uio\\&quot; clk_ignore_unused&quot;; 但我们希望其中的字段 root=/dev/mmcblk0p2 变成 root=/dev/mmcblk1p2。直觉上，首先想到的是很上文一样修改 system-user.dtsi 文件，从而影响最终生成的设备树。实验会告诉你完全不起作用，最后输出也就是实际使用的设备树里还是上面这行默认值。这里大家就会遇到 PYNQ 这个编译流程设计的很糟糕的一点：system-user.dtsi 这个文件中的只有一部分会起作用，至于想弄清哪部分，要么做实验，要么看懂编译源代码。比如上面对 &amp;sdhci1 节点的修改就能生效，对 /chosen/bootargs 对修改就不起作用。 生成设备树是制作 BSP 文件的中一部分，接下来我们来弄清楚 PYNQ 是如何生成最终的BSP文件的。我们先考虑用户没有提供预编译的 BSP 文件的情形，此时 PYNQ 内部会依次做这些事： 建立一个空的 PetaLinux 项目 拷贝用户的 petalinux_bsp/meta-user 到该项目下； 读入硬件配置即 petalinux_bsp/hardware_project 中的 XSA 文件，生成 Config 文件； 构建并打包成 BSP 文件； 利用上一步获得的 BSP 文件建立一个新的 PetaLinux 项目； 直接在脚本中修改 Config 文件，加入一些配置； 重新运行 petalinux-config 生成新的 Config 文件； 开始各种 build，最终生成我们需要的 BOOT.bin。 其中步骤1、2、3、4在 sdbuild/scripts/create_bsp.sh 脚本中进行，步骤 5、6、7、8 在 sdbuild/Makefile 中进行。如果用户指定了预编译的 BSP 文件，就把上文中的第1步换成 “利用用户提供的BSP文件建立一个新的PetaLinux项目”。这里最令人困惑的地方是，为什么要进行两次 “create-config-build” 的流程，至少我没有看出它这么做的必要性。这样一通操作之后，用户在 petalinux_bsp/meta-user 的子目录下的 system-user.dtsi 文件中修改的一些设备树节点（对应上文步骤 2），会在步骤6中被新引入的一些设备树文件冲刷掉。步骤6通过CONFIG_USER_LAYER_0这一设置混入了一些新的设备树文件，这些额外的设备树文件位于 sdbuild/boot/meta-pynq/recipes-bsp/device-tree。就 Boot 参数而言，这里边的 pynq_bootargs.dtsi 文件提供了前述的默认 /chosen/bootargs。因此无论我们在 system-user.dtsi 文件中如何修改 /chosen/bootargs，最终都会被覆盖掉。因此，我们的解决方案很简单，修改下该文件，将其中的 root=/dev/mmcblk0p2 变成 root=/dev/mmcblk1p2。因为这个文件只有几行，改动也很小，我就不把代码贴出来了。 除了修改 pynq_bootargs.dtsi，我们还需要修改 sdbuild/Makefile，将下面这行代码中的 mmcblk0p2 变成 mmcblk1p2。 Makefile1echo 'CONFIG_SUBSYSTEM_SDROOT_DEV=&quot;/dev/mmcblk0p2&quot;' &gt;&gt; $$(PL_CONFIG_$1) 我这里提供另一个有趣的思路，sdhci0 和 sdhci1 在设备树文件中是俩 alias，我们可以在设备树中交换它们的值（/amba/mmc@ff160000和/amba/mmc@ff170000），不过我没有做过实验。 UART 串口不工作EdgeBoard FZ3A 有两个 UART 串口，一个是 BT1120 连接件的一部分，另一个转成了 USB 接口。我们用来连接电脑进行交互的串口，显然希望是后者。和前面 SD 卡的情况相似，PYNQ 默认 PS_UART0 作为输出串口，而我们实际想要的是 PS_UART1。解决这个问题的方法很简单，在上面修改 CONFIG_SUBSYSTEM_SDROOT_DEV 的那行后面加上以下几行： Makefile12345echo 'CONFIG_SUBSYSTEM_PMUFW_SERIAL_PSU_UART_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1)echo 'CONFIG_SUBSYSTEM_FSBL_SERIAL_PSU_UART_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1)echo 'CONFIG_SUBSYSTEM_ATF_SERIAL_PSU_UART_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1)echo 'CONFIG_SUBSYSTEM_SERIAL_PSU_UART_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1)echo 'CONFIG_SUBSYSTEM_PRIMARY_SD_PSU_SD_1_SELECT=y' &gt;&gt; $$(PL_CONFIG_$1) dash.preinst 找不到RootFS 的编译脚本（即 create_rootfs.sh）会在前面提到的 postinst1.sh 和 postinst2.sh 两个脚本执行中提示 dash.preinst执行失败，原因是/var/lib/dpkg/info/dash.preinst找不到。该错误的原因仅仅是上游已经把dash.preinst这个脚本删除了（可参考此文）。因此这里执行该脚本的三行代码都是多余的，直接删除即可。即使不删除，它们也应当不会引起其他异常（除了在终端里输出一些错误信息）。 RootFS 分区磁盘容量不足PYNQ 在编译的最后，会对最终的镜像的 RootFS 分区进行扩容。扩容主要是增加一些用户空间，以及给操作系统本身腾出一些地方放临时文件。扩容操作是在sdbuild/scripts/resize_umount.sh脚本中进行（别问我为什么文件名中 unmount 拼写错了，源代码如此）。PYNQ 的开发者很可能是为了尽量使最终镜像小于 8GB，所以只额外扩容了 300MB。 很不幸的是，这 300MB 实在是捉襟见肘，经常开完机就用得七七八八了。极端情况下，可能不足以支撑 Jupyter 成功运行，现象是能够 ssh 访问，但浏览器完全打不开 Jupyter。排查方法是，上电后通过 ssh 进入板上的操作系统，执行 df，观察 / 分区的磁盘占用情况。 我的 SD 卡是 64GB 的，因此，我直接修改了 resize_umount.sh 脚本，将扩容空间从 300MB 改成了 3000MB。你可以根据你的 SD 卡容量自由发挥，当然没必要太大，否则烧写 SD 卡会变得很慢。具体到代码上，在该脚本中找到下面一行代码，把其中的 300 改成任意你想要的数字。 Makefile1new_size=$(( $used_size + (300 * 1024) )) 各种文件下载失败多数都是网络环境的问题，可以先阅读下一节。如果还是解决不了的话，请联系公司的IT工程师协助解决。 Speedup！编译提速在我的破笔记本上，完整的一次PYNQ流程需要整一个下午，中间还需要多次输入管理员密码。因为我们很难一次成功，所以需要不断地重新进行编译流程，所以我们总希望整个编译能够进行地快一些。接下来我们开始着手加速编译流程。 跳过输入管理员密码PYNQ编译中会频繁使用 sudo 命令，需要我们不断地输入密码，否则程序就一直卡在那等待。Ubuntu 默认两次 sudo 的时间间隔超过15分钟左右就要重新输入密码，我们可以把这个时间延长一些（比如这里我延长到了 2 小时）。 首先在 /etc/sudoers 中找到如下一行。 1Defaults env_reset 将它改成： 1Defaults env_reset,timestamp_timeout=120 为 Multistrap 更换下载源Multistrap 利用 apt 下载各种需要的包来构建 RootFS。默认情况下，apt 会从官方 ports 源（http://ports.ubuntu.com/ubuntu-ports）下载文件，时间很长且经常失败。换源的方法非常方便，直接在编译开始前声明 PYNQ_UBUNTU_REPO 环境变量即可。例如换成清华源： Terminal1❯ export PYNQ_UBUNTU_REPO=http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports 注意这里必须是 http 而不是 https。 为CrossTool-NG建立本地缓存CrossTool-NG 每次运行时会从云端下载很多包（主要是各种源代码）。根据其文档的指示，我们可以建立一个本地的缓存文件夹。当需要下载的包本地已经缓存时，它就会跳过下载，从而节省时间。CrossTool-NG 的配置文件在 sdbuild/packages/gcc-mb/samples/&lt;compile_targets&gt;/crosstool.config，在其最后加上两行： crosstool.config12CT_SAVE_TARBALLS=yCT_LOCAL_TARBALLS_DIR=&lt;somewhere_to_put_downloaded_files&gt; 注意请在运行前保证该路径是个文件夹，且具有读写权限。 为PetaLinux建立本地SSTATE缓存首先去 Xilinx 官网下载 sstate-cache 文件。注意版本要和 PetaLinux 保持一致（本文中我们用的是 2020.2）。 因为 EdgeBoard FZ3A 板载的 Zynq 芯片是 ARM64 架构，因此为了节约空间，就只下载 “aarch64 sstate-cache” 和 “downloads” 两个包（加起来也超过 60GB 了）。然后我们将它们解压缩，并把路径添加到 petalinux_bsp/meta-user/conf/petalinuxbsp.conf： petalinuxbsp.conf12DL_DIR = &quot;&lt;sstate_extract_dir&gt;/2020.2/downloads&quot;SSTATE_DIR = &quot;&lt;sstate_extract_dir&gt;/2020.2/sstate-cache/aarch64&quot; 删除 boards 目录下 Pynq-Z2 以外的开发板因为我们的编译目标是 EdgeBoard FZ3A，所以 boards 目录下的 Pynq-Z1、Pynq-Z2、ZCU104 三个目录对我们来说就是多余的。然而PYNQ在编译过程中会遍历 boards 目录下的各个开发板并试图生成比特流文件。其中 Pynq-Z2 的输出会在 pynq 自身编译时用到，另外两个开发板的相关文件的编译纯属是浪费时间（关键是这步还特别费时），我怀疑这是个编译流程上的 bug。因此，我们可以将 Pynq-Z1、ZCU104 两个文件夹删除。 Terminal12❯ cd &lt;pynq_repo_dir&gt;❯ rm -rf boards/Pynq-Z1 boards/ZCU104 完成之后，务必要提交到本地的Git版本历史中，否则不起作用（这是因为作者用 git clone 代替了 cp）。 跳过boards/Pynq-Z2中各个Overlay生成比特流pynq 作为一个 Python 的包，在编译过程中是要和其他 packages 一起安装到镜像中的。进行这一步时，它会将 Pynq 的本地 repo 先复制到 sdbuild/build/PYNQ 中，然后再运行其中的 build.sh。观察这个脚本，我们可以看到PYNQ在编译 Pynq-Z2/logictools 和 Pynq-Z2/base两个Overlay 文件夹时，会先检查其中是否已存在同名的 .bit、.hwh、.xsa 文件，存在的话就跳过生成比特流的过程（即综合、布局布线等）。因此，我们可以先按照正常流程 make BOARDDIR=... BOARDS=...，然后把生成的相关文件拷贝到原始的 boards/Pynq-Z2 目录中的对应文件夹下： Terminal123# 复制.xsa文件，.bit/.hwh文件类似处理❯ cp &lt;pynq_repo_dir&gt;/sdbuild/build/PYNQ/boards/Pynq-Z2/logictools/logictools.xsa &lt;pynq_repo_dir&gt;/boards/Pynq-Z2/logictools/❯ cp &lt;pynq_repo_dir&gt;/sdbuild/build/PYNQ/boards/Pynq-Z2/base/base.xsa &lt;pynq_repo_dir&gt;/boards/Pynq-Z2/base/ 注意这里的路径，是从 sdbuild/build 中的 PYNQ 复制到原始的 PYNQ。和前面一样，要提交到 Git 版本历史中才会生效。 另外，经过实验证明，这里 .xsa 和 .bit 文件需要是同一次编译中产生，否则会发生一些奇怪且难以定位的错误。 后记搭建这个个人博客也有几年了，本想闲暇时写些技术文章，但没能持之以恒地保持输出。中间也曾断断续续写过一些论文阅读笔记，但都没有坚持下来。一方面是因为总担心自己粗浅的专业认识贻笑大方，另一方面是实验室的项目也确实不太合适作为写作素材，便一直没有动笔。EdgeBoard 的事情我在去年 COVID 疫情期间动工后就一直搁置了，结果发现最近有不少人关心这个事情，就花了些时间算是给它画了个句号。我也以此为契机，提起了笔记录下整个过程。希望能够对大家有所帮助。","link":"/Engineering/pynq-compile/"}],"tags":[{"name":"Paper Lives Matter","slug":"Paper-Lives-Matter","link":"/tags/Paper-Lives-Matter/"},{"name":"AI Chip","slug":"AI-Chip","link":"/tags/AI-Chip/"},{"name":"Chisel","slug":"Chisel","link":"/tags/Chisel/"},{"name":"Chipmunk","slug":"Chipmunk","link":"/tags/Chipmunk/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"FPGA","slug":"FPGA","link":"/tags/FPGA/"},{"name":"PYNQ","slug":"PYNQ","link":"/tags/PYNQ/"}],"categories":[{"name":"Research","slug":"Research","link":"/categories/Research/"},{"name":"Engineering","slug":"Engineering","link":"/categories/Engineering/"}],"pages":[{"title":"About Me","text":"Welcome to my blog. I am Haozhe Zhu (朱浩哲). Currently I am a postdoctoral research fellow at Frontier Institute of Chip &amp; System, Fudan University, with Qi Liu. I am also working closely with Chixiao Chen. Most of my works lie in a overlap of integrated circuits and artificial intelligence. Education 2017-2022, Ph.D in Microelectronics and Solid-state Electronics, Fudan University, with Xiaoyang Zeng. 2013-2017, B.Eng. in Microelectronics Science &amp; Engineering, Fudan University. Selected Publications Zhu, Haozhe, Bo Jiao, Jinshan Zhang et al. “COMB-MCM: Computing-on-Memory-Boundary NN Processor with Bipolar Bitwise Sparsity Optimization for Scalable Multi-Chiplet-Module Edge Machine Learning”, In 2022 International Solid-State Circuits Conference (ISSCC), pp. 250-252, IEEE, 2022. Link Zhu, Haozhe, Chixiao Chen, Shiwei Liu et al. “A Communication-Aware DNN Accelerator on ImageNet Using in-Memory Entry-Counting Based Algorithm-Circuit-Architecture Co-Design in 65nm CMOS.” In IEEE Journal on Emerging and Selected Topics in Circuits and Systems 10, no. 3 (2020): 283-294. Link Zhu, Haozhe, Yu Wang, and C.-J. Richard Shi. “Tanji: A General-Purpose Neural Network Accelerator with a Unified Crossbar Architecture.” IEEE Design &amp; Test 37, no. 1 (2019): 56-63. Link Jiao, Bo, Haozhe Zhu, Jinshan Zhang et al. “Computing Utilization Enhancement for Chiplet-based Homogeneous Processing-in-Memory Deep Learning Processors.” In 2021 31st Great Lakes Symposium on VLSI (GLSVLSI), pp. 241-246. ACM, 2021. (Co-first author) Link Visit the Google Scholar page to view the full publication list. About This BlogAll the posts on this site only represent my personal view. They are published under the CC BY-NC-SA 4.0 license.","link":"/about/index.html"},{"title":"FICS 服务器集群使用指南","text":"访问 GitHub 以获取最新文档：cihlab/fics-cluster-guide","link":"/about/fics.html"}]}